_target_: model.models.scoring_model_esnb.ScoringModelEsnb
# num_correct: 2 # number of correct answers (e.g. 1 - raven, 2 - bongard)
# context_norm: true
# in_dim: 64
encoders:
  # - _target_: model.models.STSNv3.SlotAttentionAutoEncoder
  #   resolution:
  #     - ${img_size}
  #     - ${img_size}
  #   num_slots: 20
  #   hid_dim: 64
  #   num_iterations: 3
  #   ckpt_path: null
  #   save_hyperparameters: false
  #   save_slots: false
  #   freeze: true
  # - _target_: timm.create_model
  #   model_name: vit_large_patch32_384
  #   pretrained: true
  #   num_classes: 0
relation_module:
  _target_: model.models.ESNB.ESNB
  norm_type: tasksegmented_contextnorm
  task_seg: [[0, 1],[2, 3],[2, 4],[2, 5],[2, 6]] # VAEC/VASR
  # task_seg: [[0,1,2,3,4,5,12],[6,7,8,9,10,11,13],[0,1,2,3,4,5,13],[6,7,8,9,10,11,12]] # HOI/LOGO
  z_size: 1024
  key_size: 512
  hidden_size: 512
scoring_module:
  _target_: model.models.torch_wrappers.Sequential
  models:
    - _target_: torch.nn.Linear
      in_features: 512 # equal to hidden_size
      out_features: 256
      bias: true
    - _target_: torch.nn.ReLU
    - _target_: torch.nn.Linear
      in_features: 256
      out_features: 4 # number of classes 4 - VAEC/VASR, 1/2/4 -- HOI/LOGO
      bias: true
save_hyperparameters: true
auxiliary_loss_ratio: 0.0

# Carefully select for specific with respect to the task
# task_metric_0:
#   accuracy:
#     _target_: torchmetrics.classification.BinaryAccuracy
#     threshold: 0.5

# Example of usage with more datasets
# additional encoder and
# task_metric_1: ...
