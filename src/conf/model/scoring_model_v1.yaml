_target_: model.models.scoring_model_v1.ScoringModel
num_correct: 2 # number of correct answers (e.g. 1 - raven, 2 - bongard)
context_norm: true
in_dim: 64
slot_model:
  _target_: model.models.STSNv3.SlotAttentionAutoEncoder
  resolution:
    - ${img_size}
    - ${img_size}
  num_slots: 40
  hid_dim: 64
  num_iterations: 1
  ckpt_path: null
  save_hyperparameters: false
  save_slots: false
  freeze_slot_model: true
transformer:
  _target_: model.models.vit.ViT
  dim: 64 # hidden dimension size
  depth: 24 # transformer number of layers
  heads: 8 # transformer number of heads
  mlp_dim: 512 # transformer mlp dimension
  pool: cls
  dim_head: 32
  dropout: 0.1
  emb_dropout: 0.0
  save_hyperparameters: False
pos_emb:
  _target_: model.models.pos_emb.PositionalEmbedding
  out_dim: 64 # same as in_dim
  nrows: 7
  ncols: 2
#   ndim: null
  row_wise: true # Process row by row top to bottom (row 1 col 1 -> row 1 col2 -> ... row n col 1 -> .. row n col n) (last images - answers)
save_hyperparameters: true
auxiliary_loss_ratio: 0.0

# Carefully select for specific with respect to the task
# additional_metrics:
#   accuracy:
#     _target_: torchmetrics.classification.BinaryAccuracy
#     threshold: 0.5

# Example of usage with more datasets (different scoring layers for them) but the same backbone
# Models for second dataset
# transformer_1: ...
# pos_emb_1: ...
# additional_metrics_1: ...
# num_correct_1: ...

# Models for third dataset

# transformer_2: ...
# pos_emb_2: ...
# additional_metrics_2: ...
# num_correct_2: ...

# slots_every_n_steps: null # depricated - better to check on validation set
# slots_every_n_epochs: null # depricated - better to check on validation set
# slots_save_path: /app/out/slots
