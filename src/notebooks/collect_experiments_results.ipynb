{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=pd.core.common.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../enriched_experiments.yml\", \"r\") as f:\n",
    "    exps = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = exps[\"experiments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 345 experiments\n",
      "Unprocessed 0 experiments\n",
      "Failed 2 experiments\n"
     ]
    }
   ],
   "source": [
    "# Get all runs that produced some accuracy results\n",
    "unprocessed_count = 0\n",
    "processed_count = 0\n",
    "failed_cnt = 0\n",
    "structured_results = []\n",
    "pretrain_results = []\n",
    "for experiment in experiments:\n",
    "    if experiment.get(\"failed\"):\n",
    "        failed_cnt += 1\n",
    "        continue\n",
    "    accuracy_cols = [key for key in experiment.keys() if \"accuracy\" in key]\n",
    "    mse_cols = [key for key in experiment.keys() if \"mse\" in key]\n",
    "    loss_cols = [\n",
    "        key\n",
    "        for key in experiment.keys()\n",
    "        if \"loss\" in key and key != \"model/auxiliary_loss_ratio\"\n",
    "    ]\n",
    "\n",
    "    if len(accuracy_cols) == 0:\n",
    "        # TODO: later collect STSN runs\n",
    "        if len(mse_cols) == 0:\n",
    "            # pretraining - no loss named accuracy or mse (/loss is used)\n",
    "            pretrain_results.append(\n",
    "                {col: experiment.get(col, {}).get(\"best_loss\") for col in loss_cols}\n",
    "                | {\n",
    "                    \"loss/best_ckpt\": experiment.get(\"loss/best_ckpt\"),\n",
    "                    \"wandb_urls\": \",\".join(experiment.get(\"wandb_urls\", [])),\n",
    "                    \"experiment_nm\": experiment.get(\"experiment_nm\"),\n",
    "                    \"test_nm\": experiment.get(\"test_nm\"),\n",
    "                    \"based_on/slurm_id\": experiment.get(\"based_on\", {}).get(\"slurm_id\"),\n",
    "                    \"max_epoch\": experiment.get(\"max_epoch\"),\n",
    "                    \"lr\": experiment.get(\"lr\"),\n",
    "                    \"img_size\": experiment.get(\"img_size\"),\n",
    "                    \"batch_size\": experiment.get(\"batch_size\"),\n",
    "                    \"model/auxiliary_loss_ratio\": experiment.get(\n",
    "                        \"model/auxiliary_loss_ratio\"\n",
    "                    ),\n",
    "                    \"model/num_slots\": experiment.get(\"model/num_slots\"),\n",
    "                    \"model/num_iterations\": experiment.get(\"model/num_iterations\"),\n",
    "                    \"model/hid_dim\": experiment.get(\"model/hid_dim\"),\n",
    "                    \"model/class\": experiment.get(\"model/class\"),\n",
    "                    \"slurm_ids\": \",\".join(\n",
    "                        [str(_x) for _x in experiment.get(\"slurm_id\", [])]\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "            processed_count += 1\n",
    "        else:\n",
    "            unprocessed_count += 1\n",
    "        continue\n",
    "\n",
    "    structured_results.append(\n",
    "        {col: experiment[col][\"best_loss\"] for col in accuracy_cols}\n",
    "        | {col: experiment[col][\"best_loss\"] for col in mse_cols}\n",
    "        | {\n",
    "            \"loss/best_ckpt\": experiment.get(\"loss/best_ckpt\"),\n",
    "            \"wandb_urls\": \",\".join(experiment.get(\"wandb_urls\", [])),\n",
    "            \"experiment_nm\": experiment.get(\"experiment_nm\"),\n",
    "            \"test_nm\": experiment.get(\"test_nm\"),\n",
    "            \"based_on/slurm_id\": experiment.get(\"based_on\", {}).get(\"slurm_id\"),\n",
    "            \"max_epoch\": experiment.get(\"max_epoch\"),\n",
    "            \"finetuned_from_slurm_id\": experiment.get(\"additional_inforamations\", {})\n",
    "            .get(\"finetuned_from\", {})\n",
    "            .get(\"slurm_id\"),\n",
    "            \"finetuned_from_wandb_id\": experiment.get(\"additional_inforamations\", {})\n",
    "            .get(\"finetuned_from\", {})\n",
    "            .get(\"wandb_id\"),\n",
    "            \"lr\": experiment.get(\"lr\"),\n",
    "            \"img_size\": experiment.get(\"img_size\"),\n",
    "            \"batch_size\": experiment.get(\"batch_size\"),\n",
    "            \"model/auxiliary_loss_ratio\": experiment.get(\"model/auxiliary_loss_ratio\"),\n",
    "            \"model/class\": experiment.get(\"model/class\"),\n",
    "            \"relation-model/class\": experiment.get(\"relation-model/class\"),\n",
    "            \"val/loss\": experiment.get(\"val/loss\", {}).get(\"best_loss\"),\n",
    "            \"slurm_ids\": \",\".join([str(_x) for _x in experiment.get(\"slurm_id\", [])]),\n",
    "        }\n",
    "    )\n",
    "    # TODO: enrich with information from \"additional_inforamations\" (TODO: add relevant fields in enrich_experiments.py)\n",
    "    processed_count += 1\n",
    "print(f\"Processed {processed_count} experiments\")\n",
    "print(f\"Unprocessed {unprocessed_count} experiments\")\n",
    "print(f\"Failed {failed_cnt} experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: split by dataset (not mutually exclusive -- lets duplicate the information)\n",
    "# VAEC/VASR/HOI/LOGO/LOGO+HOI/VAEC+VASR/LOGO+VAEC/HOI+VASR\n",
    "\n",
    "# might be nice to add identifiers different than slurm_ids\n",
    "# (autoincrement value would work but could be hard to\n",
    "# automatically assign it so that it makes sense in paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_df = pd.DataFrame(pretrain_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(structured_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalize columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_cols = pretrain_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = [col for col in cols if \"train\" in col and \"accuracy\" in col]\n",
    "val_acc = [col for col in cols if \"val\" in col and \"accuracy\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = [col for col in pretrain_cols if \"train\" in col and \"loss\" in col]\n",
    "val_loss = [col for col in pretrain_cols if \"val\" in col and \"loss\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"bongard_logo\", \"bongard_hoi\", \"vaec\", \"vasr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    _cols = [col for col in train_acc if dataset in col]\n",
    "    df[f\"train/{dataset}/accuracy\"] = df[_cols].bfill(axis=1).iloc[:, 0]\n",
    "\n",
    "    _cols = [col for col in val_acc if dataset in col]\n",
    "    df[f\"val/{dataset}/accuracy\"] = df[_cols].bfill(axis=1).iloc[:, 0]\n",
    "\n",
    "    _cols = [col for col in train_loss if dataset in col]\n",
    "    pretrain_df[f\"train/{dataset}/mse\"] = pretrain_df[_cols].bfill(axis=1).iloc[:, 0]\n",
    "\n",
    "    _cols = [col for col in val_loss if dataset in col]\n",
    "    pretrain_df[f\"val/{dataset}/mse\"] = pretrain_df[_cols].bfill(axis=1).iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\n",
    "    columns=set(train_acc) - {f\"train/{dataset}/accuracy\" for dataset in datasets}\n",
    ")\n",
    "df = df.drop(columns=set(val_acc) - {f\"val/{dataset}/accuracy\" for dataset in datasets})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_df = pretrain_df.drop(columns=[*train_loss, *val_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = [col for col in cols if \"test\" in col and \"accuracy\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_types = [\n",
    "    (\"bongard_logo\", \"test_bd\"),\n",
    "    (\"bongard_logo\", \"test_ff\"),\n",
    "    (\"bongard_logo\", \"test_hd_comb\"),\n",
    "    (\"bongard_logo\", \"test_hd_novel\"),\n",
    "    (\"vaec\", \"test1\"),\n",
    "    (\"vaec\", \"test2\"),\n",
    "    (\"vaec\", \"test3\"),\n",
    "    (\"vaec\", \"test4\"),\n",
    "    (\"vaec\", \"test5\"),\n",
    "    (\"bongard_hoi\", \"seen-seen\"),\n",
    "    (\"bongard_hoi\", \"seen-unseen\"),\n",
    "    (\"bongard_hoi\", \"unseen-seen\"),\n",
    "    (\"bongard_hoi\", \"unseen-unseen\"),\n",
    "    (\"vasr\", \"vasr\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, test_type in test_types:\n",
    "    _cols = [col for col in test_acc if test_type in col]\n",
    "    df[f\"test/{dataset}/{test_type}\"] = df[_cols].bfill(axis=1).iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### enrich data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets_short = [\"logo\", \"hoi\", \"vaec\", \"vasr\"]\n",
    "\n",
    "# is_double = None\n",
    "# for _a, _b in list(combinations(datasets_short, 2)):\n",
    "#     if is_double is not None:\n",
    "#         is_double |= (df.experiment_nm.str.contains(_a)) & (df.experiment_nm.str.contains(_b))\n",
    "#     else:\n",
    "#         is_double = (df.experiment_nm.str.contains(_a)) & (df.experiment_nm.str.contains(_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_double = None\n",
    "for _a, _b in list(combinations(datasets, 2)):\n",
    "    if is_double is not None:\n",
    "        is_double |= (~pretrain_df[f\"train/{_a}/mse\"].isna()) & (\n",
    "            ~pretrain_df[f\"train/{_b}/mse\"].isna()\n",
    "        )\n",
    "    else:\n",
    "        is_double = (~pretrain_df[f\"train/{_a}/mse\"].isna()) & (\n",
    "            ~pretrain_df[f\"train/{_b}/mse\"].isna()\n",
    "        )\n",
    "pretrain_df.loc[:, \"is_double\"] = is_double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_double = None\n",
    "for _a, _b in list(combinations(datasets, 2)):\n",
    "    if is_double is not None:\n",
    "        is_double |= (~df[f\"train/{_a}/accuracy\"].isna()) & (\n",
    "            ~df[f\"train/{_b}/accuracy\"].isna()\n",
    "        )\n",
    "    else:\n",
    "        is_double = (~df[f\"train/{_a}/accuracy\"].isna()) & (\n",
    "            ~df[f\"train/{_b}/accuracy\"].isna()\n",
    "        )\n",
    "df.loc[:, \"is_double\"] = is_double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_df.loc[:, \"id\"] = \"0.\" + (pretrain_df.index + 1).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manaully append finetune? (or base it on finetune from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdatasets = [\"bongard_hoi\", \"vasr\", \"bongard_logo\", \"vaec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>model/class</th>\n",
       "      <th>img_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model/num_slots</th>\n",
       "      <th>model/num_iterations</th>\n",
       "      <th>model/hid_dim</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>train/bongard_hoi/mse</th>\n",
       "      <th>val/bongard_hoi/mse</th>\n",
       "      <th>is_double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>lr_check</td>\n",
       "      <td>STSN</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025924</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>lr_check</td>\n",
       "      <td>STSN</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020044</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>lr_check</td>\n",
       "      <td>STSN</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023244</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>lr_check</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>256</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017197</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014909</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018479</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011832</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010122</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009866</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.10</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.11</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>number_of_iterations</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019363</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.12</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>number_of_iterations</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015007</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.13</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>size_of_hid_dim</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020803</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.14</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>size_of_hid_dim</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.15</td>\n",
       "      <td>bongard_hoi_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>0.012659</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.16</td>\n",
       "      <td>bongard_hoi_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>0.020313</td>\n",
       "      <td>0.021920</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.17</td>\n",
       "      <td>bongard_hoi_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>0.012626</td>\n",
       "      <td>0.014025</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.18</td>\n",
       "      <td>bongard_hoi_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>0.011095</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.19</td>\n",
       "      <td>bongard_hoi_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>0.010046</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.20</td>\n",
       "      <td>bongard_hoi_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>0.008592</td>\n",
       "      <td>0.009695</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            experiment_nm               test_nm model/class  img_size  \\\n",
       "0    0.1  bongard_hoi_vasr_images              lr_check        STSN       256   \n",
       "1    0.2  bongard_hoi_vasr_images              lr_check        STSN       128   \n",
       "2    0.3  bongard_hoi_vasr_images              lr_check        STSN       256   \n",
       "3    0.4  bongard_hoi_vasr_images              lr_check      STSNv3       256   \n",
       "4    0.5  bongard_hoi_vasr_images       number_of_slots      STSNv3       128   \n",
       "5    0.6  bongard_hoi_vasr_images       number_of_slots      STSNv3       128   \n",
       "6    0.7  bongard_hoi_vasr_images       number_of_slots      STSNv3       128   \n",
       "7    0.8  bongard_hoi_vasr_images       number_of_slots      STSNv3       128   \n",
       "8    0.9  bongard_hoi_vasr_images       number_of_slots      STSNv3       128   \n",
       "9   0.10  bongard_hoi_vasr_images       number_of_slots      STSNv3       128   \n",
       "10  0.11  bongard_hoi_vasr_images  number_of_iterations      STSNv3       128   \n",
       "11  0.12  bongard_hoi_vasr_images  number_of_iterations      STSNv3       128   \n",
       "12  0.13  bongard_hoi_vasr_images       size_of_hid_dim      STSNv3       128   \n",
       "13  0.14  bongard_hoi_vasr_images       size_of_hid_dim      STSNv3       128   \n",
       "14  0.15       bongard_hoi_images       number_of_slots      STSNv3       128   \n",
       "15  0.16       bongard_hoi_images       number_of_slots      STSNv3       128   \n",
       "16  0.17       bongard_hoi_images       number_of_slots      STSNv3       128   \n",
       "17  0.18       bongard_hoi_images       number_of_slots      STSNv3       128   \n",
       "18  0.19       bongard_hoi_images       number_of_slots      STSNv3       128   \n",
       "19  0.20       bongard_hoi_images       number_of_slots      STSNv3       128   \n",
       "\n",
       "    batch_size  model/num_slots  model/num_iterations  model/hid_dim  \\\n",
       "0           16               20                     3             64   \n",
       "1           32               20                     3             64   \n",
       "2           16               20                     3             64   \n",
       "3            8               40                     3             64   \n",
       "4           64               20                     3             64   \n",
       "5          128               10                     3             64   \n",
       "6           32               30                     3             64   \n",
       "7           32               40                     3             64   \n",
       "8           32               50                     3             64   \n",
       "9           16               60                     3             64   \n",
       "10          64               20                     1             64   \n",
       "11          64               20                     5             64   \n",
       "12         128               20                     3             32   \n",
       "13          32               20                     3            128   \n",
       "14          64               20                     3             64   \n",
       "15         128               10                     3             64   \n",
       "16          32               30                     3             64   \n",
       "17          32               40                     3             64   \n",
       "18          32               50                     3             64   \n",
       "19          16               60                     3             64   \n",
       "\n",
       "    max_epoch  train/bongard_hoi/mse  val/bongard_hoi/mse  is_double  \n",
       "0           2               0.000000             0.025924       True  \n",
       "1           5               0.000000             0.020044       True  \n",
       "2           7               0.000000             0.023244       True  \n",
       "3           1               0.000000             0.017197       True  \n",
       "4          18               0.000000             0.014909       True  \n",
       "5          17               0.000000             0.018479       True  \n",
       "6          19               0.000000             0.011832       True  \n",
       "7          24               0.000000             0.010122       True  \n",
       "8          15               0.000000             0.009866       True  \n",
       "9          18               0.000000             0.008151       True  \n",
       "10         11               0.000000             0.019363       True  \n",
       "11         13               0.000000             0.015007       True  \n",
       "12          9               0.000000             0.020803       True  \n",
       "13         15               0.000000             0.009024       True  \n",
       "14         30               0.012659             0.014151      False  \n",
       "15          7               0.020313             0.021920      False  \n",
       "16          6               0.012626             0.014025      False  \n",
       "17          6               0.011095             0.012324      False  \n",
       "18          7               0.010046             0.011161      False  \n",
       "19          8               0.008592             0.009695      False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>model/class</th>\n",
       "      <th>img_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model/num_slots</th>\n",
       "      <th>model/num_iterations</th>\n",
       "      <th>model/hid_dim</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>train/vasr/mse</th>\n",
       "      <th>val/vasr/mse</th>\n",
       "      <th>is_double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>lr_check</td>\n",
       "      <td>STSN</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007650</td>\n",
       "      <td>0.024717</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>lr_check</td>\n",
       "      <td>STSN</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005892</td>\n",
       "      <td>0.019478</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>lr_check</td>\n",
       "      <td>STSN</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>0.006710</td>\n",
       "      <td>0.021864</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>lr_check</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>256</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004818</td>\n",
       "      <td>0.014318</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>18</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>0.012699</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>17</td>\n",
       "      <td>0.004935</td>\n",
       "      <td>0.016218</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>19</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.009839</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.008314</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.008135</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.10</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>18</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.006632</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.11</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>number_of_iterations</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.017297</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.12</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>number_of_iterations</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>13</td>\n",
       "      <td>0.004046</td>\n",
       "      <td>0.012718</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.13</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>size_of_hid_dim</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>0.005704</td>\n",
       "      <td>0.018883</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.14</td>\n",
       "      <td>bongard_hoi_vasr_images</td>\n",
       "      <td>size_of_hid_dim</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>15</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.007522</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.21</td>\n",
       "      <td>vasr_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>343</td>\n",
       "      <td>0.010089</td>\n",
       "      <td>0.009931</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.22</td>\n",
       "      <td>vasr_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>528</td>\n",
       "      <td>0.011626</td>\n",
       "      <td>0.011468</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.23</td>\n",
       "      <td>vasr_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>239</td>\n",
       "      <td>0.008390</td>\n",
       "      <td>0.008253</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.24</td>\n",
       "      <td>vasr_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>182</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.25</td>\n",
       "      <td>vasr_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>124</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            experiment_nm               test_nm model/class  img_size  \\\n",
       "0    0.1  bongard_hoi_vasr_images              lr_check        STSN       256   \n",
       "1    0.2  bongard_hoi_vasr_images              lr_check        STSN       128   \n",
       "2    0.3  bongard_hoi_vasr_images              lr_check        STSN       256   \n",
       "3    0.4  bongard_hoi_vasr_images              lr_check      STSNv3       256   \n",
       "4    0.5  bongard_hoi_vasr_images       number_of_slots      STSNv3       128   \n",
       "5    0.6  bongard_hoi_vasr_images       number_of_slots      STSNv3       128   \n",
       "6    0.7  bongard_hoi_vasr_images       number_of_slots      STSNv3       128   \n",
       "7    0.8  bongard_hoi_vasr_images       number_of_slots      STSNv3       128   \n",
       "8    0.9  bongard_hoi_vasr_images       number_of_slots      STSNv3       128   \n",
       "9   0.10  bongard_hoi_vasr_images       number_of_slots      STSNv3       128   \n",
       "10  0.11  bongard_hoi_vasr_images  number_of_iterations      STSNv3       128   \n",
       "11  0.12  bongard_hoi_vasr_images  number_of_iterations      STSNv3       128   \n",
       "12  0.13  bongard_hoi_vasr_images       size_of_hid_dim      STSNv3       128   \n",
       "13  0.14  bongard_hoi_vasr_images       size_of_hid_dim      STSNv3       128   \n",
       "20  0.21              vasr_images       number_of_slots      STSNv3       128   \n",
       "21  0.22              vasr_images       number_of_slots      STSNv3       128   \n",
       "22  0.23              vasr_images       number_of_slots      STSNv3       128   \n",
       "23  0.24              vasr_images       number_of_slots      STSNv3       128   \n",
       "24  0.25              vasr_images       number_of_slots      STSNv3       128   \n",
       "\n",
       "    batch_size  model/num_slots  model/num_iterations  model/hid_dim  \\\n",
       "0           16               20                     3             64   \n",
       "1           32               20                     3             64   \n",
       "2           16               20                     3             64   \n",
       "3            8               40                     3             64   \n",
       "4           64               20                     3             64   \n",
       "5          128               10                     3             64   \n",
       "6           32               30                     3             64   \n",
       "7           32               40                     3             64   \n",
       "8           32               50                     3             64   \n",
       "9           16               60                     3             64   \n",
       "10          64               20                     1             64   \n",
       "11          64               20                     5             64   \n",
       "12         128               20                     3             32   \n",
       "13          32               20                     3            128   \n",
       "20          64               20                     3             64   \n",
       "21         128               10                     3             64   \n",
       "22          32               30                     3             64   \n",
       "23          32               40                     3             64   \n",
       "24          16               60                     3             64   \n",
       "\n",
       "    max_epoch  train/vasr/mse  val/vasr/mse  is_double  \n",
       "0           2        0.007650      0.024717       True  \n",
       "1           5        0.005892      0.019478       True  \n",
       "2           7        0.006710      0.021864       True  \n",
       "3           1        0.004818      0.014318       True  \n",
       "4          18        0.004018      0.012699       True  \n",
       "5          17        0.004935      0.016218       True  \n",
       "6          19        0.003141      0.009839       True  \n",
       "7          24        0.002693      0.008314       True  \n",
       "8          15        0.002618      0.008135       True  \n",
       "9          18        0.002202      0.006632       True  \n",
       "10         11        0.005339      0.017297       True  \n",
       "11         13        0.004046      0.012718       True  \n",
       "12          9        0.005704      0.018883       True  \n",
       "13         15        0.002445      0.007522       True  \n",
       "20        343        0.010089      0.009931      False  \n",
       "21        528        0.011626      0.011468      False  \n",
       "22        239        0.008390      0.008253      False  \n",
       "23        182        0.007463      0.007327      False  \n",
       "24        124        0.006104      0.006027      False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>model/class</th>\n",
       "      <th>img_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model/num_slots</th>\n",
       "      <th>model/num_iterations</th>\n",
       "      <th>model/hid_dim</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>train/bongard_logo/mse</th>\n",
       "      <th>val/bongard_logo/mse</th>\n",
       "      <th>is_double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.26</td>\n",
       "      <td>bongard_logo_vaec_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>70</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.27</td>\n",
       "      <td>bongard_logo_vaec_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.002539</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.28</td>\n",
       "      <td>bongard_logo_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>165</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.29</td>\n",
       "      <td>bongard_logo_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>77</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id             experiment_nm          test_nm model/class  img_size  \\\n",
       "25  0.26  bongard_logo_vaec_images  number_of_slots      STSNv3        80   \n",
       "26  0.27  bongard_logo_vaec_images  number_of_slots      STSNv3        80   \n",
       "27  0.28       bongard_logo_images  number_of_slots      STSNv3        80   \n",
       "28  0.29       bongard_logo_images  number_of_slots      STSNv3        80   \n",
       "\n",
       "    batch_size  model/num_slots  model/num_iterations  model/hid_dim  \\\n",
       "25         128               20                     3             64   \n",
       "26         256               10                     3             64   \n",
       "27         256               10                     3             64   \n",
       "28         128               20                     3             64   \n",
       "\n",
       "    max_epoch  train/bongard_logo/mse  val/bongard_logo/mse  is_double  \n",
       "25         70                0.000256              0.000834       True  \n",
       "26         60                0.000696              0.002539       True  \n",
       "27        165                0.001149              0.001245      False  \n",
       "28         77                0.001243              0.001227      False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>model/class</th>\n",
       "      <th>img_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model/num_slots</th>\n",
       "      <th>model/num_iterations</th>\n",
       "      <th>model/hid_dim</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>train/vaec/mse</th>\n",
       "      <th>val/vaec/mse</th>\n",
       "      <th>is_double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.26</td>\n",
       "      <td>bongard_logo_vaec_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>70</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.27</td>\n",
       "      <td>bongard_logo_vaec_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.30</td>\n",
       "      <td>vaec_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>47</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.31</td>\n",
       "      <td>vaec_images</td>\n",
       "      <td>number_of_slots</td>\n",
       "      <td>STSNv3</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>34</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id             experiment_nm          test_nm model/class  img_size  \\\n",
       "25  0.26  bongard_logo_vaec_images  number_of_slots      STSNv3        80   \n",
       "26  0.27  bongard_logo_vaec_images  number_of_slots      STSNv3        80   \n",
       "29  0.30               vaec_images  number_of_slots      STSNv3        80   \n",
       "30  0.31               vaec_images  number_of_slots      STSNv3        80   \n",
       "\n",
       "    batch_size  model/num_slots  model/num_iterations  model/hid_dim  \\\n",
       "25         128               20                     3             64   \n",
       "26         256               10                     3             64   \n",
       "29         256               10                     3             64   \n",
       "30         128               20                     3             64   \n",
       "\n",
       "    max_epoch  train/vaec/mse  val/vaec/mse  is_double  \n",
       "25         70        0.000259      0.000920       True  \n",
       "26         60        0.000702      0.001655       True  \n",
       "29         47        0.000007      0.001268      False  \n",
       "30         34        0.000004      0.001885      False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dataset in sdatasets:\n",
    "    cols = [\n",
    "        # \"wandb_urls\",\n",
    "        \"id\",\n",
    "        \"experiment_nm\",\n",
    "        \"test_nm\",\n",
    "        # \"based_on/slurm_id\",\n",
    "        \"model/class\",\n",
    "        \"img_size\",\n",
    "        \"batch_size\",\n",
    "        # \"model/auxiliary_loss_ratio\",\n",
    "        \"model/num_slots\",\n",
    "        \"model/num_iterations\",\n",
    "        \"model/hid_dim\",\n",
    "        \"max_epoch\",\n",
    "        f\"train/{dataset}/mse\",\n",
    "        f\"val/{dataset}/mse\",\n",
    "        \"is_double\",\n",
    "    ]\n",
    "    _df = pretrain_df[cols]\n",
    "    # _df[\"model/auxiliary_loss_ratio\"].fillna(0, inplace=True)\n",
    "    _df = _df.dropna()\n",
    "    _df.dataset = dataset\n",
    "    _df[\"model/class\"] = _df[\"model/class\"].str.split(\".\").str[2]\n",
    "    _df.max_epoch = _df.max_epoch.astype(\"Int32\")\n",
    "    display(_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in sdatasets:\n",
    "    cols = [\n",
    "        # \"wandb_urls\",\n",
    "        \"id\",\n",
    "        # \"experiment_nm\",\n",
    "        \"test_nm\",\n",
    "        \"is_double\",\n",
    "        # \"based_on/slurm_id\",\n",
    "        \"lr\",\n",
    "        \"model/class\",\n",
    "        \"img_size\",\n",
    "        \"batch_size\",\n",
    "        \"max_epoch\",\n",
    "        # \"model/auxiliary_loss_ratio\",\n",
    "        \"model/num_slots\",\n",
    "        \"model/num_iterations\",\n",
    "        \"model/hid_dim\",\n",
    "        f\"train/{dataset}/mse\",\n",
    "        f\"val/{dataset}/mse\",\n",
    "    ]\n",
    "    _df = pretrain_df[cols]\n",
    "    # _df[\"model/auxiliary_loss_ratio\"].fillna(0, inplace=True)\n",
    "    _df = _df.dropna(subset=[f\"train/{dataset}/mse\", f\"val/{dataset}/mse\"])\n",
    "    _df.dataset = dataset\n",
    "    _df.max_epoch = _df.max_epoch.astype(\"Int32\")\n",
    "    _df[\"model/class\"] = _df[\"model/class\"].str.split(\".\").str[2]\n",
    "    _df.max_epoch = _df.max_epoch.astype(\"Int32\")\n",
    "    # _df.wandb_urls = _df.wandb_urls.str.split(\"/\").str[-1]\n",
    "    out = []\n",
    "    for column in _df.columns:\n",
    "        splt = column.split(\"/\")\n",
    "        if len(splt) == 3:\n",
    "            out.append((splt[0], splt[1], splt[2]))\n",
    "        elif len(splt) == 2:\n",
    "            if splt[0] in [\"train\", \"val\", \"test\"]:\n",
    "                out.append((splt[0], \"\", splt[1]))\n",
    "                continue\n",
    "            if column == \"model/auxilary_loss_ratio\":\n",
    "                out.append((\"auxiliary\", \"loss\", \"ratio\"))\n",
    "                continue\n",
    "            out.append((\"\", splt[0], splt[1]))\n",
    "        else:\n",
    "            if column == \"finetune_from\":\n",
    "                out.append((\"\", \"finetune\", \"from\"))\n",
    "                continue\n",
    "            out.append((\"\", \"\", splt[0]))\n",
    "    _df.columns = pd.MultiIndex.from_tuples(out)\n",
    "\n",
    "    print(f\"\\n%{'-'*20} {dataset} {'-'*20}\\n\")\n",
    "\n",
    "    lr_prec = 5 if _df[(\"\", \"\", \"lr\")].min() < 1e-5 else 4\n",
    "    _tbl = (\n",
    "        _df.style.highlight_min(\n",
    "            subset=[\n",
    "                (\"train\", dataset, \"mse\"),\n",
    "                (\"val\", dataset, \"mse\"),\n",
    "            ],\n",
    "            axis=0,\n",
    "            props=\"textbf:--rwrap;\",\n",
    "        )\n",
    "        .format(\n",
    "            subset=[\n",
    "                (\"train\", dataset, \"mse\"),\n",
    "                (\"val\", dataset, \"mse\"),\n",
    "            ],\n",
    "            precision=5,\n",
    "        )\n",
    "        .format(\n",
    "            subset=[(\"\", \"\", \"lr\")],\n",
    "            precision=lr_prec,\n",
    "        )\n",
    "        .hide()\n",
    "        .to_latex(\n",
    "            caption=f\"Pretraining results for {dataset}\",\n",
    "            hrules=True,\n",
    "            label=f\"tab:pretrain-{dataset.replace('_', '-')}\",\n",
    "            # siunitx=True,\n",
    "        )\n",
    "        .replace(\"number_of\", \"no\")\n",
    "        .replace(\"no_iterations\", \"no_iter\")\n",
    "        .replace(\"_\", \"\\\\_\")\n",
    "    )\n",
    "    # add \\resizebox{\\textwidth}{!}{% ... } between tabular and end tabular\n",
    "    _tbl = _tbl.replace(\n",
    "        r\"\\begin{tabular}\",\n",
    "        r\"\"\"\\resizebox{\\textwidth}{!}{%\n",
    "\\begin{tabular}\"\"\",\n",
    "    )\n",
    "    _tbl = _tbl.replace(\n",
    "        r\"\\end{tabular}\",\n",
    "        r\"\"\"\\end{tabular}\n",
    "}\"\"\",\n",
    "    )\n",
    "\n",
    "    print(_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "_mapper_df = pd.concat(\n",
    "    (pretrain_df[\"id\"], pretrain_df[\"slurm_ids\"].str.split(\",\").explode()), axis=1\n",
    ")\n",
    "\n",
    "slurm_id_to_expr_map = _mapper_df.set_index(\"slurm_ids\").to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STSN - 1.1 - 1.N\n",
    "\n",
    "ix = (\n",
    "    (~df.experiment_nm.str.contains(\"combined\"))\n",
    "    & (~df.experiment_nm.str.contains(\"esnb\"))\n",
    "    & (~df.experiment_nm.str.contains(\"finetune\"))\n",
    "    & (\n",
    "        df[\"model/class\"]\n",
    "        != \"model.models.baseline_scoring_modules_v2.BaselineScoringModel\"\n",
    "    )\n",
    ")\n",
    "ids_connected = df.loc[ix, :].slurm_ids.str.split(\",\").explode().astype(\"Int32\")\n",
    "slurm_id_to_idx_map = (\n",
    "    ids_connected.reset_index().set_index(\"slurm_ids\").to_dict()[\"index\"]\n",
    ")\n",
    "\n",
    "ix2 = (df.experiment_nm == \"finetune\") & (\n",
    "    df[\"finetuned_from_slurm_id\"].isin(ids_connected)\n",
    ")\n",
    "df_stsn = df[(ix) | (ix2)]\n",
    "df_stsn.loc[:, \"id\"] = [f\"1.{_x}\" for _x in range(1, len(df_stsn) + 1)]\n",
    "# based on mapping\n",
    "df_stsn.loc[:, \"based_on\"] = (\n",
    "    df_stsn[\"based_on/slurm_id\"]\n",
    "    .astype(\"Int32\")\n",
    "    .astype(str)\n",
    "    .apply(lambda x: slurm_id_to_expr_map[\"id\"].get(x, None))\n",
    ")\n",
    "finetune_ix = ~pd.isna(df_stsn.finetuned_from_slurm_id)\n",
    "df_stsn.loc[finetune_ix, \"finetune_from\"] = (\n",
    "    df_stsn.loc[finetune_ix, :]\n",
    "    .finetuned_from_slurm_id.astype(\"Int32\")\n",
    "    .apply(lambda x: df_stsn.loc[slurm_id_to_idx_map.get(x, None), \"id\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in sdatasets:\n",
    "    cols = [\n",
    "        # \"wandb_urls\",\n",
    "        \"id\",\n",
    "        # \"experiment_nm\",\n",
    "        \"test_nm\",\n",
    "        # \"based_on/slurm_id\",\n",
    "        \"based_on\",\n",
    "        \"finetune_from\",\n",
    "        \"is_double\",\n",
    "        # \"model/class\",\n",
    "        \"img_size\",\n",
    "        \"batch_size\",\n",
    "        \"model/auxiliary_loss_ratio\",\n",
    "        # \"model/num_slots\",\n",
    "        # \"model/num_iterations\",\n",
    "        # \"model/hid_dim\",\n",
    "        \"max_epoch\",\n",
    "        \"val/loss\",\n",
    "        f\"train/{dataset}/accuracy\",\n",
    "        f\"val/{dataset}/accuracy\",\n",
    "        # TODO: Add Test results for each regime)\n",
    "    ]\n",
    "    test_cols = [\n",
    "        f\"test/{dataset}/{test_type}\"\n",
    "        for test_type in map(\n",
    "            lambda x: x[1], filter(lambda x: x[0] == dataset, test_types)\n",
    "        )\n",
    "    ]\n",
    "    _df = df_stsn[[*cols, *test_cols]]\n",
    "    _df[\"model/auxiliary_loss_ratio\"] = (\n",
    "        _df[\"model/auxiliary_loss_ratio\"].fillna(0).astype(\"int\")\n",
    "    )\n",
    "    _df = _df.dropna(subset=[f\"train/{dataset}/accuracy\", f\"val/{dataset}/accuracy\"])\n",
    "    _df.dataset = dataset\n",
    "    # _df[\"model/class\"] = _df[\"model/class\"].str.split(\".\").str[3]\n",
    "    _df.max_epoch = _df.max_epoch.astype(\"Int32\")\n",
    "    _df.finetune_from = _df.finetune_from.combine_first(_df.based_on)\n",
    "    _df.drop(columns=[\"based_on\"], inplace=True)\n",
    "\n",
    "    out = []\n",
    "    for column in _df.columns:\n",
    "        splt = column.split(\"/\")\n",
    "        if len(splt) == 3:\n",
    "            out.append((splt[0], splt[1], splt[2]))\n",
    "        elif len(splt) == 2:\n",
    "            if splt[0] in [\"train\", \"val\", \"test\"]:\n",
    "                out.append((splt[0], \"\", splt[1]))\n",
    "                continue\n",
    "            if column == \"model/auxilary_loss_ratio\":\n",
    "                out.append((\"auxiliary\", \"loss\", \"ratio\"))\n",
    "                continue\n",
    "            out.append((\"\", splt[0], splt[1]))\n",
    "        else:\n",
    "            if column == \"finetune_from\":\n",
    "                out.append((\"\", \"finetune\", \"from\"))\n",
    "                continue\n",
    "            out.append((\"\", \"\", splt[0]))\n",
    "    _df.columns = pd.MultiIndex.from_tuples(out)\n",
    "    # _df.loc[:,\"test\"] = _df.apply(\n",
    "    #     lambda x: f'{\", \".join([f\"{x[col]:.2%}\" for col in test_cols if not pd.isna(x[col])])}',\n",
    "    #     axis=1,\n",
    "    # )\n",
    "    # _df.wandb_urls = _df.wandb_urls.str.split(\"/\").str[-1]\n",
    "    print(f\"\\n%{'-'*20} {dataset} {'-'*20}\\n\")\n",
    "\n",
    "    _highlight_max = [\n",
    "        f\"train/{dataset}/accuracy\",\n",
    "        f\"val/{dataset}/accuracy\",\n",
    "        *test_cols,\n",
    "    ]\n",
    "    _highlight_max = [col.split(\"/\") for col in _highlight_max]\n",
    "    _tbl = (\n",
    "        _df.style.highlight_max(\n",
    "            # subset=[f\"train/{dataset}/accuracy\", f\"val/{dataset}/accuracy\", *test_cols],\n",
    "            subset=_highlight_max,\n",
    "            axis=0,\n",
    "            props=\"textbf:--rwrap;\",\n",
    "        )\n",
    "        .highlight_min(\n",
    "            subset=[(\"val\", \"\", \"loss\")],\n",
    "            axis=0,\n",
    "            props=\"textbf:--rwrap;\",\n",
    "        )\n",
    "        .hide()\n",
    "        .format(\n",
    "            formatter=\"{:.2%}\".format,\n",
    "            subset=[\n",
    "                *_highlight_max,\n",
    "                (\"train\", dataset, \"accuracy\"),\n",
    "                (\"val\", dataset, \"accuracy\"),\n",
    "            ],\n",
    "        )\n",
    "        .format(subset=[(\"val\", \"\", \"loss\")], precision=3)\n",
    "        .to_latex(\n",
    "            caption=f\"Classification results for {dataset}\",\n",
    "            hrules=True,\n",
    "            label=f\"tab:stsn-{dataset.replace('_', '-')}\",\n",
    "            # siunitx=True,\n",
    "            # column_format=\"lp{0.5cm}p{1.8cm}p{1.5cm}p{1.0cm}p{0.7cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.6cm}p{0.4cm}p{0.4cm}p{0.5cm}\"\n",
    "            # + len(test_cols) * \"p{0.4cm}\",\n",
    "            multicol_align=\"c\",\n",
    "        )\n",
    "        .replace(\"train_\", \"\")\n",
    "        .replace(\"trained_\", \"\")\n",
    "        .replace(\"_test\", \"\")\n",
    "        .replace(\"finetune_on_single_task_based_on_dual\", \"finetune\")\n",
    "        .replace(\"_\", \"\\\\_\")\n",
    "        .replace(\"nan%\", \"---\")\n",
    "        .replace(\"nan\", \"---\")\n",
    "        .replace(\"None\", \"---\")\n",
    "        .replace(\"%\", \"\\%\")\n",
    "    )\n",
    "    # add \\resizebox{\\textwidth}{!}{% ... } between tabular and end tabular\n",
    "    _tbl = _tbl.replace(\n",
    "        r\"\\begin{tabular}\",\n",
    "        r\"\"\"\\resizebox{\\textwidth}{!}{%\n",
    "\\begin{tabular}\"\"\",\n",
    "    )\n",
    "\n",
    "    _tbl = _tbl.replace(\n",
    "        r\"\\end{tabular}\",\n",
    "        r\"\"\"\\end{tabular}\n",
    "}\"\"\",\n",
    "    )\n",
    "\n",
    "    # display(_df.shape)\n",
    "    # display(_df)\n",
    "    print(_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in sdatasets:\n",
    "    cols = [\n",
    "        \"wandb_urls\",\n",
    "        \"id\",\n",
    "        \"experiment_nm\",\n",
    "        \"test_nm\",\n",
    "        # \"based_on/slurm_id\",\n",
    "        \"model/class\",\n",
    "        \"img_size\",\n",
    "        \"batch_size\",\n",
    "        \"model/auxiliary_loss_ratio\",\n",
    "        # \"model/num_slots\",\n",
    "        # \"model/num_iterations\",\n",
    "        # \"model/hid_dim\",\n",
    "        \"max_epoch\",\n",
    "        \"val/loss\",\n",
    "        f\"train/{dataset}/accuracy\",\n",
    "        f\"val/{dataset}/accuracy\",\n",
    "        # TODO: Add Test results for each regime)\n",
    "        \"based_on\",\n",
    "        \"finetune_from\",\n",
    "        \"is_double\",\n",
    "    ]\n",
    "    test_cols = [\n",
    "        f\"test/{dataset}/{test_type}\"\n",
    "        for test_type in map(\n",
    "            lambda x: x[1], filter(lambda x: x[0] == dataset, test_types)\n",
    "        )\n",
    "    ]\n",
    "    _df = df_stsn[[*cols, *test_cols]]\n",
    "    _df[\"model/auxiliary_loss_ratio\"] = (\n",
    "        _df[\"model/auxiliary_loss_ratio\"].fillna(0).astype(\"int\")\n",
    "    )\n",
    "    _df = _df.dropna(subset=[f\"train/{dataset}/accuracy\", f\"val/{dataset}/accuracy\"])\n",
    "    _df.dataset = dataset\n",
    "    _df[\"model/class\"] = _df[\"model/class\"].str.split(\".\").str[3]\n",
    "    _df.max_epoch = _df.max_epoch.astype(\"Int32\")\n",
    "    _df.wandb_urls = _df.wandb_urls.str.split(\"/\").str[-1]\n",
    "    out = []\n",
    "    for column in _df.columns:\n",
    "        splt = column.split(\"/\")\n",
    "        if len(splt) == 3:\n",
    "            out.append((splt[0], splt[1], splt[2]))\n",
    "        elif len(splt) == 2:\n",
    "            if splt[0] in [\"train\", \"val\", \"test\"]:\n",
    "                out.append((splt[0], \"\", splt[1]))\n",
    "                continue\n",
    "            if column == \"model/auxilary_loss_ratio\":\n",
    "                out.append((\"auxiliary\", \"loss\", \"ratio\"))\n",
    "                continue\n",
    "            out.append((\"\", splt[0], splt[1]))\n",
    "        else:\n",
    "            out.append((\"\", \"\", splt[0]))\n",
    "    _df.columns = pd.MultiIndex.from_tuples(out)\n",
    "    # _df.loc[:,\"test\"] = _df.apply(\n",
    "    #     lambda x: f'{\", \".join([f\"{x[col]:.2%}\" for col in test_cols if not pd.isna(x[col])])}',\n",
    "    #     axis=1,\n",
    "    # )\n",
    "    # _df.wandb_urls = _df.wandb_urls.str.split(\"/\").str[-1]\n",
    "    print(f\"\\n%{'-'*20} {dataset} {'-'*20}\\n\")\n",
    "\n",
    "    _highlight_max = [\n",
    "        f\"train/{dataset}/accuracy\",\n",
    "        f\"val/{dataset}/accuracy\",\n",
    "        *test_cols,\n",
    "    ]\n",
    "    _highlight_max = [col.split(\"/\") for col in _highlight_max]\n",
    "    _tbl = (\n",
    "        _df.style.highlight_max(\n",
    "            # subset=[f\"train/{dataset}/accuracy\", f\"val/{dataset}/accuracy\", *test_cols],\n",
    "            subset=_highlight_max,\n",
    "            axis=0,\n",
    "            props=\"textbf:--rwrap;\",\n",
    "        )\n",
    "        .highlight_min(\n",
    "            subset=[(\"val\", \"\", \"loss\")],\n",
    "            axis=0,\n",
    "            props=\"textbf:--rwrap;\",\n",
    "        )\n",
    "        .hide()\n",
    "        .format(\n",
    "            formatter=\"{:.2%}\".format,\n",
    "            subset=[\n",
    "                *_highlight_max,\n",
    "                (\"train\", dataset, \"accuracy\"),\n",
    "                (\"val\", dataset, \"accuracy\"),\n",
    "            ],\n",
    "        )\n",
    "        .to_latex(\n",
    "            caption=f\"Classification results for {dataset}\",\n",
    "            hrules=True,\n",
    "            label=f\"tab:pretrain-{dataset.replace('_', '-')}\",\n",
    "            # siunitx=True,\n",
    "            # column_format=\"lp{0.5cm}p{1.8cm}p{1.5cm}p{1.0cm}p{0.7cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.6cm}p{0.4cm}p{0.4cm}p{0.5cm}\"\n",
    "            # + len(test_cols) * \"p{0.4cm}\",\n",
    "            multicol_align=\"c\",\n",
    "        )\n",
    "        .replace(\"_\", \"\\\\_\")\n",
    "        .replace(\"nan%\", \"---\")\n",
    "        .replace(\"nan\", \"---\")\n",
    "        .replace(\"%\", \"\\%\")\n",
    "    )\n",
    "    # add \\resizebox{\\textwidth}{!}{% ... } between tabular and end tabular\n",
    "    _tbl = _tbl.replace(\n",
    "        r\"\\begin{tabular}\",\n",
    "        r\"\"\"\\resizebox{\\textwidth}{!}{%\n",
    "\\begin{tabular}\"\"\",\n",
    "    )\n",
    "\n",
    "    _tbl = _tbl.replace(\n",
    "        r\"\\end{tabular}\",\n",
    "        r\"\"\"\\end{tabular}\n",
    "}\"\"\",\n",
    "    )\n",
    "\n",
    "    display(_df.shape)\n",
    "    display(_df)\n",
    "    # print(_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESNB - 2.1 - 2.N\n",
    "\n",
    "ix = (\n",
    "    # (~df.experiment_nm.str.contains(\"combined\"))\n",
    "    df.experiment_nm.str.contains(\"esnb\")\n",
    "    # & (~df.experiment_nm.str.contains(\"finetune\"))\n",
    "    # & (\n",
    "    #     df[\"model/class\"]\n",
    "    #     != \"model.models.baseline_scoring_modules_v2.BaselineScoringModel\"\n",
    "    # )\n",
    ")\n",
    "ids_connected = df.loc[ix, :].slurm_ids.str.split(\",\").explode().astype(\"Int32\")\n",
    "slurm_id_to_idx_map = (\n",
    "    ids_connected.reset_index().set_index(\"slurm_ids\").to_dict()[\"index\"]\n",
    ")\n",
    "\n",
    "ix2 = (df.experiment_nm == \"finetune\") & (\n",
    "    df[\"finetuned_from_slurm_id\"].isin(ids_connected)\n",
    ")\n",
    "df_esnb = df[(ix) | (ix2)]\n",
    "df_esnb.loc[:, \"id\"] = [f\"2.{_x}\" for _x in range(1, len(df_esnb) + 1)]\n",
    "# based on mapping\n",
    "df_esnb.loc[:, \"based_on\"] = (\n",
    "    df_esnb[\"based_on/slurm_id\"]\n",
    "    .astype(\"Int32\")\n",
    "    .astype(str)\n",
    "    .apply(lambda x: slurm_id_to_expr_map[\"id\"].get(x, None))\n",
    ")\n",
    "finetune_ix = ~pd.isna(df_esnb.finetuned_from_slurm_id)\n",
    "df_esnb.loc[finetune_ix, \"finetune_from\"] = (\n",
    "    df_esnb.loc[finetune_ix, :]\n",
    "    .finetuned_from_slurm_id.astype(\"Int32\")\n",
    "    .apply(lambda x: df_esnb.loc[slurm_id_to_idx_map.get(x, None), \"id\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "%-------------------- bongard_hoi --------------------\n",
      "\n",
      "\\begin{table}\n",
      "\\caption{Classification results with relation module for bongard\\_hoi. is\\_double columns informs if training was done on bongard\\_hoi and bongard logo dataset. Finetune from column informs if experiment was based on existing on, if it is 0.N - then it means and encoder was pretrained, if it is 1.N - then it means whole STSN was trained in 1.N experiment. Bold text mean best result in column.}\n",
      "\\label{tab:esbn-bongard-hoi}\n",
      "\\resizebox{\\textwidth}{!}{%\n",
      "\\begin{tabular}{lllrlrrrrrrrr}\n",
      "\\toprule\n",
      "\\multicolumn{6}{c}{} & val & train & val & \\multicolumn{4}{c}{test} \\\\\n",
      "\\multicolumn{2}{c}{} & finetune &  & relation-model &  &  & bongard\\_hoi & bongard\\_hoi & \\multicolumn{4}{c}{bongard\\_hoi} \\\\\n",
      "id & test\\_nm & from & is\\_double & class & max\\_epoch & loss & accuracy & accuracy & seen-seen & seen-unseen & unseen-seen & unseen-unseen \\\\\n",
      "\\midrule\n",
      "2.3 & esbn\\_single & --- & False & ESNB & 216 & \\textbf{0.471} & 86.08\\% & \\textbf{78.28\\%} & 61.22\\% & \\textbf{66.50\\%} & \\textbf{63.35\\%} & \\textbf{66.50\\%} \\\\\n",
      "2.5 & esbn\\_dual & 0.28 & True & ESNB & 17 & 0.693 & 50.76\\% & 51.73\\% & 50.36\\% & 49.88\\% & 50.35\\% & 49.88\\% \\\\\n",
      "2.6 & esbn\\_dual & 0.29 & True & ESNB & 11 & 0.693 & 50.76\\% & 51.73\\% & 50.36\\% & 49.88\\% & 50.35\\% & 49.88\\% \\\\\n",
      "2.7 & esbn\\_dual & --- & True & ESNB & 17 & 0.632 & 66.31\\% & 66.96\\% & 61.44\\% & 62.41\\% & 61.38\\% & 62.41\\% \\\\\n",
      "2.16 & esbn\\_single\\_2 & --- & False & ESNB & 499 & 0.628 & \\textbf{100.00\\%} & 66.37\\% & 61.95\\% & 64.08\\% & 61.95\\% & 64.08\\% \\\\\n",
      "2.20 & esbn\\_single\\_2 & --- & False & ESNB & 499 & 0.611 & \\textbf{100.00\\%} & 66.52\\% & 61.05\\% & 65.01\\% & 61.05\\% & 65.01\\% \\\\\n",
      "2.23 & esbn\\_dual\\_2 & --- & True & ESNB & 499 & 0.652 & \\textbf{100.00\\%} & 64.43\\% & 61.46\\% & 63.83\\% & 61.46\\% & 63.83\\% \\\\\n",
      "2.25 & esbn\\_dual\\_2 & --- & True & ESNB & 499 & 0.645 & \\textbf{100.00\\%} & 64.90\\% & 60.11\\% & 63.96\\% & 60.11\\% & 63.96\\% \\\\\n",
      "2.28 & esbnv2\\_single & --- & False & ESNBv2 & 499 & 0.625 & 99.91\\% & 66.70\\% & 61.40\\% & 63.52\\% & 61.40\\% & 63.52\\% \\\\\n",
      "2.31 & esbnv2\\_dual & --- & True & ESNBv2 & 499 & 0.653 & 99.86\\% & 65.17\\% & 61.14\\% & 62.90\\% & 61.14\\% & 62.90\\% \\\\\n",
      "2.34 & esbnv2\\_single-lower\\_lr & --- & False & ESNBv2 & 499 & 0.632 & 99.64\\% & 66.64\\% & 61.42\\% & 63.90\\% & 61.42\\% & 63.90\\% \\\\\n",
      "2.37 & esbnv2\\_dual-lower\\_lr & --- & True & ESNBv2 & 499 & 0.657 & 99.68\\% & 65.37\\% & 61.55\\% & 64.21\\% & 61.55\\% & 64.21\\% \\\\\n",
      "2.40 & esbnv2\\_single-smaller\\ & --- & False & ESNBv2 & 499 & 0.625 & 99.96\\% & 66.43\\% & 62.01\\% & 63.83\\% & 62.01\\% & 63.83\\% \\\\\n",
      "2.43 & esbnv2\\_dual-smaller\\ & --- & True & ESNBv2 & 499 & 0.648 & 99.83\\% & 64.40\\% & 61.49\\% & 64.14\\% & 61.49\\% & 64.14\\% \\\\\n",
      "2.46 & finetune & 2.23 & False & ESNB & 499 & 0.632 & \\textbf{100.00\\%} & 66.11\\% & 61.07\\% & 64.14\\% & 61.07\\% & 64.14\\% \\\\\n",
      "2.48 & finetune & 2.25 & False & ESNB & 360 & 0.617 & \\textbf{100.00\\%} & 65.81\\% & \\textbf{62.78\\%} & 64.95\\% & 62.78\\% & 64.95\\% \\\\\n",
      "2.50 & finetune & 2.31 & False & ESNBv2 & 499 & 0.629 & 99.89\\% & 66.61\\% & 61.62\\% & 64.45\\% & 61.62\\% & 64.45\\% \\\\\n",
      "2.52 & finetune & 2.37 & False & ESNBv2 & 499 & 0.633 & 99.82\\% & 66.37\\% & 62.10\\% & 65.38\\% & 62.10\\% & 65.38\\% \\\\\n",
      "2.54 & finetune & 2.43 & False & ESNBv2 & 499 & 0.621 & 99.88\\% & 66.67\\% & 61.55\\% & 64.33\\% & 61.55\\% & 64.33\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "%-------------------- vasr --------------------\n",
      "\n",
      "\\begin{table}\n",
      "\\caption{Classification results with relation module for vasr. is\\_double columns informs if training was done on vasr and bongard logo dataset. Finetune from column informs if experiment was based on existing on, if it is 0.N - then it means and encoder was pretrained, if it is 1.N - then it means whole STSN was trained in 1.N experiment. Bold text mean best result in column.}\n",
      "\\label{tab:esbn-vasr}\n",
      "\\resizebox{\\textwidth}{!}{%\n",
      "\\begin{tabular}{lllrlrrrrr}\n",
      "\\toprule\n",
      "\\multicolumn{6}{c}{} & val & train & val & test \\\\\n",
      "\\multicolumn{2}{c}{} & finetune &  & relation-model &  &  & vasr & vasr & vasr \\\\\n",
      "id & test\\_nm & from & is\\_double & class & max\\_epoch & loss & accuracy & accuracy & vasr \\\\\n",
      "\\midrule\n",
      "2.10 & esbn\\_single & 0.31 & False & ESNB & 50 & 1.274 & 56.02\\% & 39.25\\% & 38.86\\% \\\\\n",
      "2.12 & esbn\\_dual & 0.30 & True & ESNB & 2 & 1.386 & 24.93\\% & 25.17\\% & 25.17\\% \\\\\n",
      "2.13 & esbn\\_dual & 0.31 & True & ESNB & 1 & 1.386 & 24.93\\% & 25.17\\% & 25.17\\% \\\\\n",
      "2.14 & esbn\\_dual & --- & True & ESNB & 4 & 1.297 & 31.19\\% & 30.34\\% & 30.84\\% \\\\\n",
      "2.18 & esbn\\_single\\_2 & --- & False & ESNB & 499 & \\textbf{1.242} & 88.15\\% & 40.25\\% & 39.33\\% \\\\\n",
      "2.22 & esbn\\_single\\_2 & --- & False & ESNB & 466 & 1.252 & \\textbf{99.60\\%} & 40.08\\% & 38.51\\% \\\\\n",
      "2.24 & esbn\\_dual\\_2 & --- & True & ESNB & 499 & 1.360 & 61.37\\% & 36.34\\% & 31.40\\% \\\\\n",
      "2.26 & esbn\\_dual\\_2 & --- & True & ESNB & 247 & 1.365 & 68.60\\% & 34.21\\% & 31.02\\% \\\\\n",
      "2.30 & esbnv2\\_single & --- & False & ESNBv2 & 216 & 1.253 & 47.18\\% & 39.81\\% & 38.04\\% \\\\\n",
      "2.32 & esbnv2\\_dual & --- & True & ESNBv2 & 112 & 1.262 & 40.49\\% & \\textbf{40.48\\%} & 35.36\\% \\\\\n",
      "2.36 & esbnv2\\_single-lower\\_lr & --- & False & ESNBv2 & 216 & 1.252 & 44.41\\% & 38.87\\% & 38.25\\% \\\\\n",
      "2.38 & esbnv2\\_dual-lower\\_lr & --- & True & ESNBv2 & 112 & 1.276 & 39.68\\% & 38.67\\% & 35.22\\% \\\\\n",
      "2.42 & esbnv2\\_single-smaller\\ & --- & False & ESNBv2 & 499 & 1.252 & 51.42\\% & 39.57\\% & 38.39\\% \\\\\n",
      "2.44 & esbnv2\\_dual-smaller\\ & --- & True & ESNBv2 & 404 & 1.278 & 55.10\\% & 39.92\\% & --- \\\\\n",
      "2.56 & finetune & 2.24 & False & ESNB & 202 & 1.244 & 61.46\\% & 40.01\\% & \\textbf{39.73\\%} \\\\\n",
      "2.58 & finetune & 2.26 & False & ESNB & 58 & 1.311 & 44.88\\% & 35.63\\% & 35.05\\% \\\\\n",
      "2.60 & finetune & 2.32 & False & ESNBv2 & 30 & 1.248 & 38.16\\% & 39.11\\% & 38.97\\% \\\\\n",
      "2.62 & finetune & 2.38 & False & ESNBv2 & 30 & 1.261 & 37.74\\% & 38.42\\% & 38.42\\% \\\\\n",
      "2.64 & finetune & 2.44 & False & ESNBv2 & 97 & 1.257 & 42.37\\% & 39.35\\% & 38.58\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "%-------------------- bongard_logo --------------------\n",
      "\n",
      "\\begin{table}\n",
      "\\caption{Classification results with relation module for bongard\\_logo. is\\_double columns informs if training was done on bongard\\_logo and bongard logo dataset. Finetune from column informs if experiment was based on existing on, if it is 0.N - then it means and encoder was pretrained, if it is 1.N - then it means whole STSN was trained in 1.N experiment. Bold text mean best result in column.}\n",
      "\\label{tab:esbn-bongard-logo}\n",
      "\\resizebox{\\textwidth}{!}{%\n",
      "\\begin{tabular}{lllrlrrrrrrrr}\n",
      "\\toprule\n",
      "\\multicolumn{6}{c}{} & val & train & val & \\multicolumn{4}{c}{test} \\\\\n",
      "\\multicolumn{2}{c}{} & finetune &  & relation-model &  &  & bongard\\_logo & bongard\\_logo & \\multicolumn{4}{c}{bongard\\_logo} \\\\\n",
      "id & test\\_nm & from & is\\_double & class & max\\_epoch & loss & accuracy & accuracy & test\\_bd & test\\_ff & test\\_hd\\_comb & test\\_hd\\_novel \\\\\n",
      "\\midrule\n",
      "2.1 & esbn\\_single & 0.28 & False & ESNB & 242 & 0.691 & 51.44\\% & 54.78\\% & 45.83\\% & 48.50\\% & 45.50\\% & 45.31\\% \\\\\n",
      "2.2 & esbn\\_single & 0.29 & False & ESNB & 67 & 1.382 & 51.52\\% & 52.44\\% & 53.12\\% & 53.33\\% & 54.25\\% & \\textbf{56.56\\%} \\\\\n",
      "2.4 & esbn\\_single & --- & False & ESNB & 292 & 0.663 & 60.04\\% & \\textbf{61.67\\%} & \\textbf{58.54\\%} & 55.67\\% & --- & --- \\\\\n",
      "2.5 & esbn\\_dual & 0.28 & True & ESNB & 17 & 0.693 & 50.73\\% & 52.56\\% & 48.33\\% & 49.00\\% & 50.00\\% & 48.75\\% \\\\\n",
      "2.6 & esbn\\_dual & 0.29 & True & ESNB & 11 & 0.693 & 50.73\\% & 52.56\\% & 48.33\\% & 49.00\\% & 50.00\\% & 48.75\\% \\\\\n",
      "2.7 & esbn\\_dual & --- & True & ESNB & 17 & \\textbf{0.632} & 57.92\\% & 58.78\\% & 58.33\\% & 52.83\\% & --- & --- \\\\\n",
      "2.15 & esbn\\_single\\_2 & --- & False & ESNB & 499 & 0.670 & \\textbf{100.00\\%} & 56.78\\% & 55.42\\% & 52.50\\% & 52.75\\% & 50.94\\% \\\\\n",
      "2.19 & esbn\\_single\\_2 & --- & False & ESNB & 499 & 0.670 & \\textbf{100.00\\%} & 56.22\\% & 52.50\\% & 50.50\\% & 53.25\\% & 53.75\\% \\\\\n",
      "2.23 & esbn\\_dual\\_2 & --- & True & ESNB & 499 & 0.652 & \\textbf{100.00\\%} & 57.67\\% & 54.17\\% & 51.83\\% & 50.75\\% & 53.12\\% \\\\\n",
      "2.25 & esbn\\_dual\\_2 & --- & True & ESNB & 499 & 0.645 & \\textbf{100.00\\%} & 57.33\\% & 54.79\\% & 49.50\\% & 50.25\\% & 51.25\\% \\\\\n",
      "2.27 & esbnv2\\_single & --- & False & ESNBv2 & 499 & 0.662 & 99.99\\% & 58.22\\% & 52.50\\% & 51.67\\% & 52.50\\% & 53.12\\% \\\\\n",
      "2.31 & esbnv2\\_dual & --- & True & ESNBv2 & 499 & 0.653 & 99.98\\% & 58.78\\% & 52.50\\% & 52.00\\% & 48.25\\% & 54.06\\% \\\\\n",
      "2.33 & esbnv2\\_single-lower\\_lr & --- & False & ESNBv2 & 499 & 0.667 & 99.83\\% & 57.00\\% & 54.37\\% & 52.67\\% & 55.00\\% & 52.19\\% \\\\\n",
      "2.37 & esbnv2\\_dual-lower\\_lr & --- & True & ESNBv2 & 499 & 0.657 & 99.95\\% & 57.56\\% & 54.17\\% & 50.00\\% & 49.75\\% & 52.50\\% \\\\\n",
      "2.39 & esbnv2\\_single-smaller\\ & --- & False & ESNBv2 & 499 & 0.661 & \\textbf{100.00\\%} & 57.78\\% & 53.54\\% & 53.00\\% & \\textbf{55.50\\%} & 53.75\\% \\\\\n",
      "2.43 & esbnv2\\_dual-smaller\\ & --- & True & ESNBv2 & 499 & 0.648 & 99.99\\% & 59.22\\% & 52.92\\% & 52.83\\% & 49.00\\% & 53.75\\% \\\\\n",
      "2.45 & finetune & 2.23 & False & ESNB & 499 & 0.678 & \\textbf{100.00\\%} & 57.22\\% & 58.13\\% & \\textbf{56.67\\%} & 52.75\\% & 52.50\\% \\\\\n",
      "2.47 & finetune & 2.25 & False & ESNB & 499 & 0.664 & \\textbf{100.00\\%} & 56.33\\% & 54.58\\% & 52.67\\% & 51.00\\% & 50.94\\% \\\\\n",
      "2.49 & finetune & 2.31 & False & ESNBv2 & 499 & 0.677 & 99.97\\% & 58.11\\% & 54.79\\% & 53.83\\% & 54.75\\% & 53.44\\% \\\\\n",
      "2.51 & finetune & 2.37 & False & ESNBv2 & 499 & 0.676 & 99.82\\% & 59.00\\% & 55.21\\% & 53.33\\% & 50.75\\% & 54.69\\% \\\\\n",
      "2.53 & finetune & 2.43 & False & ESNBv2 & 499 & 0.678 & 99.94\\% & 58.89\\% & 56.67\\% & 53.50\\% & 52.75\\% & 53.44\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "%-------------------- vaec --------------------\n",
      "\n",
      "\\begin{table}\n",
      "\\caption{Classification results with relation module for vaec. is\\_double columns informs if training was done on vaec and bongard logo dataset. Finetune from column informs if experiment was based on existing on, if it is 0.N - then it means and encoder was pretrained, if it is 1.N - then it means whole STSN was trained in 1.N experiment. Bold text mean best result in column.}\n",
      "\\label{tab:esbn-vaec}\n",
      "\\resizebox{\\textwidth}{!}{%\n",
      "\\begin{tabular}{lllrlrrrrrrrrr}\n",
      "\\toprule\n",
      "\\multicolumn{6}{c}{} & val & train & val & \\multicolumn{5}{c}{test} \\\\\n",
      "\\multicolumn{2}{c}{} & finetune &  & relation-model &  &  & vaec & vaec & \\multicolumn{5}{c}{vaec} \\\\\n",
      "id & test\\_nm & from & is\\_double & class & max\\_epoch & loss & accuracy & accuracy & test1 & test2 & test3 & test4 & test5 \\\\\n",
      "\\midrule\n",
      "2.8 & esbn\\_single & 0.30 & False & ESNB & 241 & 1.386 & 25.00\\% & 25.00\\% & 25.00\\% & 25.00\\% & 25.00\\% & 25.00\\% & 25.00\\% \\\\\n",
      "2.9 & esbn\\_single & 0.31 & False & ESNB & 114 & 1.386 & 25.00\\% & 25.00\\% & 25.00\\% & 25.00\\% & 25.00\\% & 25.00\\% & 25.00\\% \\\\\n",
      "2.11 & esbn\\_single & --- & False & ESNB & 184 & 1.326 & 40.97\\% & 35.54\\% & 34.91\\% & 36.40\\% & 37.26\\% & 32.78\\% & 35.07\\% \\\\\n",
      "2.12 & esbn\\_dual & 0.30 & True & ESNB & 2 & 1.386 & 25.10\\% & 25.14\\% & 24.80\\% & 24.80\\% & 24.80\\% & 24.80\\% & 24.80\\% \\\\\n",
      "2.13 & esbn\\_dual & 0.31 & True & ESNB & 1 & 1.386 & 25.01\\% & 24.91\\% & 24.80\\% & 24.80\\% & 24.80\\% & 24.80\\% & 24.80\\% \\\\\n",
      "2.14 & esbn\\_dual & --- & True & ESNB & 4 & 1.297 & 35.80\\% & 31.78\\% & 32.71\\% & 34.52\\% & 35.32\\% & 29.59\\% & 33.23\\% \\\\\n",
      "2.17 & esbn\\_single\\_2 & --- & False & ESNB & 499 & 1.351 & 48.65\\% & 33.87\\% & 32.96\\% & 35.09\\% & 35.41\\% & 31.33\\% & 32.75\\% \\\\\n",
      "2.21 & esbn\\_single\\_2 & --- & False & ESNB & 499 & 1.346 & 51.59\\% & 34.03\\% & 33.42\\% & 34.60\\% & 35.29\\% & 31.79\\% & 33.34\\% \\\\\n",
      "2.24 & esbn\\_dual\\_2 & --- & True & ESNB & 499 & 1.360 & \\textbf{99.51\\%} & 35.44\\% & 32.36\\% & 34.09\\% & 34.93\\% & 30.51\\% & 32.59\\% \\\\\n",
      "2.26 & esbn\\_dual\\_2 & --- & True & ESNB & 247 & 1.365 & 96.71\\% & 35.67\\% & 32.38\\% & 34.52\\% & 34.13\\% & 30.70\\% & 32.99\\% \\\\\n",
      "2.29 & esbnv2\\_single & --- & False & ESNBv2 & 499 & \\textbf{1.222} & 75.30\\% & 45.63\\% & 43.99\\% & 45.30\\% & 45.88\\% & 42.66\\% & 45.44\\% \\\\\n",
      "2.32 & esbnv2\\_dual & --- & True & ESNBv2 & 112 & 1.262 & 91.86\\% & 46.41\\% & 41.68\\% & 43.58\\% & 44.72\\% & 41.07\\% & 44.47\\% \\\\\n",
      "2.35 & esbnv2\\_single-lower\\_lr & --- & False & ESNBv2 & 499 & 1.245 & 74.54\\% & 44.73\\% & 41.85\\% & 42.20\\% & 43.57\\% & 40.17\\% & 43.25\\% \\\\\n",
      "2.38 & esbnv2\\_dual-lower\\_lr & --- & True & ESNBv2 & 112 & 1.276 & 86.40\\% & 44.86\\% & 41.68\\% & 43.90\\% & 44.38\\% & 41.12\\% & 44.19\\% \\\\\n",
      "2.41 & esbnv2\\_single-smaller\\ & --- & False & ESNBv2 & 499 & 1.259 & 71.32\\% & 45.48\\% & 42.13\\% & 42.92\\% & 43.36\\% & 40.17\\% & 43.43\\% \\\\\n",
      "2.44 & esbnv2\\_dual-smaller\\ & --- & True & ESNBv2 & 404 & 1.278 & 97.29\\% & \\textbf{46.77\\%} & 38.99\\% & 40.61\\% & 41.38\\% & 38.09\\% & 40.82\\% \\\\\n",
      "2.55 & finetune & 2.24 & False & ESNB & 499 & 1.350 & 48.80\\% & 34.15\\% & 33.11\\% & 35.36\\% & 36.15\\% & 31.59\\% & 33.46\\% \\\\\n",
      "2.57 & finetune & 2.26 & False & ESNB & 499 & 1.352 & 51.15\\% & 33.95\\% & 33.70\\% & 35.63\\% & 36.02\\% & 32.11\\% & 33.80\\% \\\\\n",
      "2.59 & finetune & 2.32 & False & ESNBv2 & 450 & 1.228 & 75.35\\% & 45.76\\% & \\textbf{44.53\\%} & \\textbf{46.29\\%} & \\textbf{46.31\\%} & \\textbf{43.19\\%} & \\textbf{45.73\\%} \\\\\n",
      "2.61 & finetune & 2.38 & False & ESNBv2 & 456 & 1.257 & 74.70\\% & 45.00\\% & 42.89\\% & 44.55\\% & 45.22\\% & 41.68\\% & 44.94\\% \\\\\n",
      "2.63 & finetune & 2.44 & False & ESNBv2 & 499 & 1.259 & 71.36\\% & 45.17\\% & 41.39\\% & 42.72\\% & 43.21\\% & 40.39\\% & 42.41\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in sdatasets:\n",
    "    cols = [\n",
    "        # \"wandb_urls\",\n",
    "        \"id\",\n",
    "        # \"experiment_nm\",\n",
    "        \"test_nm\",\n",
    "        # \"based_on/slurm_id\",\n",
    "        \"based_on\",\n",
    "        \"finetune_from\",\n",
    "        \"is_double\",\n",
    "        \"relation-model/class\",\n",
    "        # \"img_size\",\n",
    "        # \"batch_size\",\n",
    "        # \"model/auxiliary_loss_ratio\",\n",
    "        # \"model/num_slots\",\n",
    "        # \"model/num_iterations\",\n",
    "        # \"model/hid_dim\",\n",
    "        \"max_epoch\",\n",
    "        \"val/loss\",\n",
    "        f\"train/{dataset}/accuracy\",\n",
    "        f\"val/{dataset}/accuracy\",\n",
    "        # TODO: Add Test results for each regime)\n",
    "    ]\n",
    "    test_cols = [\n",
    "        f\"test/{dataset}/{test_type}\"\n",
    "        for test_type in map(\n",
    "            lambda x: x[1], filter(lambda x: x[0] == dataset, test_types)\n",
    "        )\n",
    "    ]\n",
    "    _df = df_esnb[[*cols, *test_cols]]\n",
    "    # _df[\"model/auxiliary_loss_ratio\"] = (\n",
    "    #     _df[\"model/auxiliary_loss_ratio\"].fillna(0).astype(\"int\")\n",
    "    # )\n",
    "    _df = _df.dropna(subset=[f\"train/{dataset}/accuracy\", f\"val/{dataset}/accuracy\"])\n",
    "    _df.dataset = dataset\n",
    "    _df[\"relation-model/class\"] = _df[\"relation-model/class\"].str.split(\".\").str[2]\n",
    "    _df.max_epoch = _df.max_epoch.astype(\"Int32\")\n",
    "    _df.finetune_from = _df.finetune_from.combine_first(_df.based_on)\n",
    "    _df.drop(columns=[\"based_on\"], inplace=True)\n",
    "    out = []\n",
    "    for column in _df.columns:\n",
    "        splt = column.split(\"/\")\n",
    "        if len(splt) == 3:\n",
    "            out.append((splt[0], splt[1], splt[2]))\n",
    "        elif len(splt) == 2:\n",
    "            if splt[0] in [\"train\", \"val\", \"test\"]:\n",
    "                out.append((splt[0], \"\", splt[1]))\n",
    "                continue\n",
    "            if column == \"model/auxilary_loss_ratio\":\n",
    "                out.append((\"auxiliary\", \"loss\", \"ratio\"))\n",
    "                continue\n",
    "            out.append((\"\", splt[0], splt[1]))\n",
    "        else:\n",
    "            if column == \"finetune_from\":\n",
    "                out.append((\"\", \"finetune\", \"from\"))\n",
    "                continue\n",
    "            out.append((\"\", \"\", splt[0]))\n",
    "    _df.columns = pd.MultiIndex.from_tuples(out)\n",
    "    # _df.loc[:,\"test\"] = _df.apply(\n",
    "    #     lambda x: f'{\", \".join([f\"{x[col]:.2%}\" for col in test_cols if not pd.isna(x[col])])}',\n",
    "    #     axis=1,\n",
    "    # )\n",
    "    # _df.wandb_urls = _df.wandb_urls.str.split(\"/\").str[-1]\n",
    "    print(f\"\\n%{'-'*20} {dataset} {'-'*20}\\n\")\n",
    "\n",
    "    _highlight_max = [\n",
    "        f\"train/{dataset}/accuracy\",\n",
    "        f\"val/{dataset}/accuracy\",\n",
    "        *test_cols,\n",
    "    ]\n",
    "    _highlight_max = [col.split(\"/\") for col in _highlight_max]\n",
    "    _tbl = (\n",
    "        _df.style.highlight_max(\n",
    "            # subset=[f\"train/{dataset}/accuracy\", f\"val/{dataset}/accuracy\", *test_cols],\n",
    "            subset=_highlight_max,\n",
    "            axis=0,\n",
    "            props=\"textbf:--rwrap;\",\n",
    "        )\n",
    "        .highlight_min(\n",
    "            subset=[(\"val\", \"\", \"loss\")],\n",
    "            axis=0,\n",
    "            props=\"textbf:--rwrap;\",\n",
    "        )\n",
    "        .hide()\n",
    "        .format(\n",
    "            formatter=\"{:.2%}\".format,\n",
    "            subset=[\n",
    "                *_highlight_max,\n",
    "                (\"train\", dataset, \"accuracy\"),\n",
    "                (\"val\", dataset, \"accuracy\"),\n",
    "            ],\n",
    "        )\n",
    "        .format(subset=[(\"val\", \"\", \"loss\")], precision=3)\n",
    "        .to_latex(\n",
    "            caption=f\"Classification results with relation module for {dataset}. is_double columns informs if training was done on {dataset} and bongard logo dataset. Finetune from column informs if experiment was based on existing on, if it is 0.N - then it means and encoder was pretrained, if it is 1.N - then it means whole STSN was trained in 1.N experiment. Bold text mean best result in column.\",\n",
    "            hrules=True,\n",
    "            label=f\"tab:esbn-{dataset.replace('_', '-')}\",\n",
    "            # siunitx=True,\n",
    "            # column_format=\"lp{0.5cm}p{1.8cm}p{1.5cm}p{1.0cm}p{0.7cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.6cm}p{0.4cm}p{0.4cm}p{0.5cm}\"\n",
    "            # + len(test_cols) * \"p{0.4cm}\",\n",
    "            multicol_align=\"c\",\n",
    "        )\n",
    "        .replace(\"finetune_on_single_task_based_on_dual\", \"finetune\")\n",
    "        .replace(\"relation_\", \"\")\n",
    "        .replace(\"_\", \"\\\\_\")\n",
    "        .replace(\"nan%\", \"---\")\n",
    "        .replace(\"nan\", \"---\")\n",
    "        .replace(\"None\", \"---\")\n",
    "        .replace(\"_scoring\", \"\")\n",
    "        .replace(\"%\", \"\\%\")\n",
    "        .replace(\"esnb\", \"esbn\")\n",
    "    )\n",
    "    # add \\resizebox{\\textwidth}{!}{% ... } between tabular and end tabular\n",
    "    _tbl = _tbl.replace(\n",
    "        r\"\\begin{tabular}\",\n",
    "        r\"\"\"\\resizebox{\\textwidth}{!}{%\n",
    "\\begin{tabular}\"\"\",\n",
    "    )\n",
    "\n",
    "    _tbl = _tbl.replace(\n",
    "        r\"\\end{tabular}\",\n",
    "        r\"\"\"\\end{tabular}\n",
    "}\"\"\",\n",
    "    )\n",
    "\n",
    "    # display(_df.shape)\n",
    "    # display(_df)\n",
    "    print(_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "%-------------------- bongard_hoi --------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19, 18)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\"></th>\n",
       "      <th>val</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th colspan=\"4\" halign=\"left\">test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\"></th>\n",
       "      <th>relation-model</th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th></th>\n",
       "      <th>bongard_hoi</th>\n",
       "      <th>bongard_hoi</th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th colspan=\"4\" halign=\"left\">bongard_hoi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>wandb_urls</th>\n",
       "      <th>id</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>class</th>\n",
       "      <th>img_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>based_on</th>\n",
       "      <th>finetune_from</th>\n",
       "      <th>is_double</th>\n",
       "      <th>seen-seen</th>\n",
       "      <th>seen-unseen</th>\n",
       "      <th>unseen-seen</th>\n",
       "      <th>unseen-unseen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>cmyrffip</td>\n",
       "      <td>2.3</td>\n",
       "      <td>bongard_hoi_scoring_esnb</td>\n",
       "      <td>relation_esnb_single</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>216</td>\n",
       "      <td>0.471449</td>\n",
       "      <td>0.860813</td>\n",
       "      <td>0.782775</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.612154</td>\n",
       "      <td>0.665012</td>\n",
       "      <td>0.633494</td>\n",
       "      <td>0.665012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>o0oz8bt5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>bongard_logo_hoi_scoring_esnb</td>\n",
       "      <td>relation_esnb_dual</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>0.692726</td>\n",
       "      <td>0.507617</td>\n",
       "      <td>0.517343</td>\n",
       "      <td>0.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.503575</td>\n",
       "      <td>0.498759</td>\n",
       "      <td>0.503507</td>\n",
       "      <td>0.498759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>h78u70gc</td>\n",
       "      <td>2.6</td>\n",
       "      <td>bongard_logo_hoi_scoring_esnb</td>\n",
       "      <td>relation_esnb_dual</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.692724</td>\n",
       "      <td>0.507617</td>\n",
       "      <td>0.517343</td>\n",
       "      <td>0.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.503575</td>\n",
       "      <td>0.498759</td>\n",
       "      <td>0.503507</td>\n",
       "      <td>0.498759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>tiji5vvm</td>\n",
       "      <td>2.7</td>\n",
       "      <td>bongard_logo_hoi_scoring_esnb_vit</td>\n",
       "      <td>relation_esnb_dual</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>0.632098</td>\n",
       "      <td>0.663079</td>\n",
       "      <td>0.669606</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.614388</td>\n",
       "      <td>0.624069</td>\n",
       "      <td>0.613766</td>\n",
       "      <td>0.624069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>zasa73hq</td>\n",
       "      <td>2.16</td>\n",
       "      <td>bongard_hoi_scoring_esnb-2</td>\n",
       "      <td>relation_esnb_single_2</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>0.628341</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.663727</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.619465</td>\n",
       "      <td>0.640819</td>\n",
       "      <td>0.619465</td>\n",
       "      <td>0.640819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>vrdj235f</td>\n",
       "      <td>2.20</td>\n",
       "      <td>bongard_hoi_scoring_esnb-2_larger</td>\n",
       "      <td>relation_esnb_single_2</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>499</td>\n",
       "      <td>0.610504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.665197</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.610478</td>\n",
       "      <td>0.650124</td>\n",
       "      <td>0.610478</td>\n",
       "      <td>0.650124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>7byrc875</td>\n",
       "      <td>2.23</td>\n",
       "      <td>bongard_logo_hoi_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnb_dual_2</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>0.652056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.644327</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.614643</td>\n",
       "      <td>0.638337</td>\n",
       "      <td>0.614643</td>\n",
       "      <td>0.638337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>8cjb18ld</td>\n",
       "      <td>2.25</td>\n",
       "      <td>bongard_logo_hoi_scoring_esnb_vit-2_larger</td>\n",
       "      <td>relation_esnb_dual_2</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>499</td>\n",
       "      <td>0.644687</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.649030</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.601052</td>\n",
       "      <td>0.639578</td>\n",
       "      <td>0.601052</td>\n",
       "      <td>0.639578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>9btos9yk</td>\n",
       "      <td>2.28</td>\n",
       "      <td>bongard_hoi_scoring_esnb-2</td>\n",
       "      <td>relation_esnbv2_single</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>0.624779</td>\n",
       "      <td>0.999132</td>\n",
       "      <td>0.666961</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.613985</td>\n",
       "      <td>0.635236</td>\n",
       "      <td>0.613985</td>\n",
       "      <td>0.635236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>bzd3toty</td>\n",
       "      <td>2.31</td>\n",
       "      <td>bongard_logo_hoi_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnbv2_dual</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>0.653035</td>\n",
       "      <td>0.998606</td>\n",
       "      <td>0.651675</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.611355</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.611355</td>\n",
       "      <td>0.629032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>qvd7p9sj</td>\n",
       "      <td>2.34</td>\n",
       "      <td>bongard_hoi_scoring_esnb-2</td>\n",
       "      <td>relation_esnbv2_single-lower_lr</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>0.632106</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.666373</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.614204</td>\n",
       "      <td>0.638958</td>\n",
       "      <td>0.614204</td>\n",
       "      <td>0.638958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>17cweqpi</td>\n",
       "      <td>2.37</td>\n",
       "      <td>bongard_logo_hoi_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnbv2_dual-lower_lr</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>0.657176</td>\n",
       "      <td>0.996834</td>\n",
       "      <td>0.653733</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.615520</td>\n",
       "      <td>0.642060</td>\n",
       "      <td>0.615520</td>\n",
       "      <td>0.642060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>ja04uq50</td>\n",
       "      <td>2.40</td>\n",
       "      <td>bongard_hoi_scoring_esnb-2</td>\n",
       "      <td>relation_esnbv2_single-smaller_scoring</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>0.624969</td>\n",
       "      <td>0.999566</td>\n",
       "      <td>0.664315</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.620123</td>\n",
       "      <td>0.638337</td>\n",
       "      <td>0.620123</td>\n",
       "      <td>0.638337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>15masdov</td>\n",
       "      <td>2.43</td>\n",
       "      <td>bongard_logo_hoi_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnbv2_dual-smaller_scoring</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>0.648287</td>\n",
       "      <td>0.998301</td>\n",
       "      <td>0.644033</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.614862</td>\n",
       "      <td>0.641439</td>\n",
       "      <td>0.614862</td>\n",
       "      <td>0.641439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>iy4s2fxn</td>\n",
       "      <td>2.46</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>0.631882</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.661082</td>\n",
       "      <td>None</td>\n",
       "      <td>2.23</td>\n",
       "      <td>False</td>\n",
       "      <td>0.610697</td>\n",
       "      <td>0.641439</td>\n",
       "      <td>0.610697</td>\n",
       "      <td>0.641439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>dgvh2xt0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>360</td>\n",
       "      <td>0.617002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.658142</td>\n",
       "      <td>None</td>\n",
       "      <td>2.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.627795</td>\n",
       "      <td>0.649504</td>\n",
       "      <td>0.627795</td>\n",
       "      <td>0.649504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>vuai30ub</td>\n",
       "      <td>2.50</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>0.629114</td>\n",
       "      <td>0.998872</td>\n",
       "      <td>0.666079</td>\n",
       "      <td>None</td>\n",
       "      <td>2.31</td>\n",
       "      <td>False</td>\n",
       "      <td>0.616177</td>\n",
       "      <td>0.644541</td>\n",
       "      <td>0.616177</td>\n",
       "      <td>0.644541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>zc9h12ss</td>\n",
       "      <td>2.52</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>0.633218</td>\n",
       "      <td>0.998177</td>\n",
       "      <td>0.663727</td>\n",
       "      <td>None</td>\n",
       "      <td>2.37</td>\n",
       "      <td>False</td>\n",
       "      <td>0.621000</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.621000</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>lg90tnul</td>\n",
       "      <td>2.54</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>0.621043</td>\n",
       "      <td>0.998785</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>None</td>\n",
       "      <td>2.43</td>\n",
       "      <td>False</td>\n",
       "      <td>0.615520</td>\n",
       "      <td>0.643300</td>\n",
       "      <td>0.615520</td>\n",
       "      <td>0.643300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  \\\n",
       "                                                                   \n",
       "    wandb_urls    id                               experiment_nm   \n",
       "72    cmyrffip   2.3                    bongard_hoi_scoring_esnb   \n",
       "74    o0oz8bt5   2.5               bongard_logo_hoi_scoring_esnb   \n",
       "75    h78u70gc   2.6               bongard_logo_hoi_scoring_esnb   \n",
       "76    tiji5vvm   2.7           bongard_logo_hoi_scoring_esnb_vit   \n",
       "85    zasa73hq  2.16                  bongard_hoi_scoring_esnb-2   \n",
       "89    vrdj235f  2.20           bongard_hoi_scoring_esnb-2_larger   \n",
       "92    7byrc875  2.23         bongard_logo_hoi_scoring_esnb_vit-2   \n",
       "94    8cjb18ld  2.25  bongard_logo_hoi_scoring_esnb_vit-2_larger   \n",
       "97    9btos9yk  2.28                  bongard_hoi_scoring_esnb-2   \n",
       "100   bzd3toty  2.31         bongard_logo_hoi_scoring_esnb_vit-2   \n",
       "103   qvd7p9sj  2.34                  bongard_hoi_scoring_esnb-2   \n",
       "106   17cweqpi  2.37         bongard_logo_hoi_scoring_esnb_vit-2   \n",
       "109   ja04uq50  2.40                  bongard_hoi_scoring_esnb-2   \n",
       "112   15masdov  2.43         bongard_logo_hoi_scoring_esnb_vit-2   \n",
       "295   iy4s2fxn  2.46                                    finetune   \n",
       "297   dgvh2xt0  2.48                                    finetune   \n",
       "299   vuai30ub  2.50                                    finetune   \n",
       "301   zc9h12ss  2.52                                    finetune   \n",
       "303   lg90tnul  2.54                                    finetune   \n",
       "\n",
       "                                                                     \\\n",
       "                                            relation-model            \n",
       "                                    test_nm          class img_size   \n",
       "72                     relation_esnb_single           ESNB       80   \n",
       "74                       relation_esnb_dual           ESNB       80   \n",
       "75                       relation_esnb_dual           ESNB       80   \n",
       "76                       relation_esnb_dual           ESNB       80   \n",
       "85                   relation_esnb_single_2           ESNB       80   \n",
       "89                   relation_esnb_single_2           ESNB       80   \n",
       "92                     relation_esnb_dual_2           ESNB       80   \n",
       "94                     relation_esnb_dual_2           ESNB       80   \n",
       "97                   relation_esnbv2_single         ESNBv2       80   \n",
       "100                    relation_esnbv2_dual         ESNBv2       80   \n",
       "103         relation_esnbv2_single-lower_lr         ESNBv2       80   \n",
       "106           relation_esnbv2_dual-lower_lr         ESNBv2       80   \n",
       "109  relation_esnbv2_single-smaller_scoring         ESNBv2       80   \n",
       "112    relation_esnbv2_dual-smaller_scoring         ESNBv2       80   \n",
       "295   finetune_on_single_task_based_on_dual           ESNB       80   \n",
       "297   finetune_on_single_task_based_on_dual           ESNB       80   \n",
       "299   finetune_on_single_task_based_on_dual         ESNBv2       80   \n",
       "301   finetune_on_single_task_based_on_dual         ESNBv2       80   \n",
       "303   finetune_on_single_task_based_on_dual         ESNBv2       80   \n",
       "\n",
       "                               val       train         val           \\\n",
       "                                   bongard_hoi bongard_hoi            \n",
       "    batch_size max_epoch      loss    accuracy    accuracy based_on   \n",
       "72          16       216  0.471449    0.860813    0.782775     None   \n",
       "74           8        17  0.692726    0.507617    0.517343     0.28   \n",
       "75           8        11  0.692724    0.507617    0.517343     0.29   \n",
       "76           4        17  0.632098    0.663079    0.669606     None   \n",
       "85         256       499  0.628341    1.000000    0.663727     None   \n",
       "89         128       499  0.610504    1.000000    0.665197     None   \n",
       "92         256       499  0.652056    1.000000    0.644327     None   \n",
       "94         128       499  0.644687    1.000000    0.649030     None   \n",
       "97         256       499  0.624779    0.999132    0.666961     None   \n",
       "100        256       499  0.653035    0.998606    0.651675     None   \n",
       "103        256       499  0.632106    0.996354    0.666373     None   \n",
       "106        256       499  0.657176    0.996834    0.653733     None   \n",
       "109        256       499  0.624969    0.999566    0.664315     None   \n",
       "112        256       499  0.648287    0.998301    0.644033     None   \n",
       "295        256       499  0.631882    1.000000    0.661082     None   \n",
       "297        128       360  0.617002    1.000000    0.658142     None   \n",
       "299        256       499  0.629114    0.998872    0.666079     None   \n",
       "301        256       499  0.633218    0.998177    0.663727     None   \n",
       "303        256       499  0.621043    0.998785    0.666667     None   \n",
       "\n",
       "                                   test                                        \n",
       "                            bongard_hoi                                        \n",
       "    finetune_from is_double   seen-seen seen-unseen unseen-seen unseen-unseen  \n",
       "72            NaN     False    0.612154    0.665012    0.633494      0.665012  \n",
       "74            NaN      True    0.503575    0.498759    0.503507      0.498759  \n",
       "75            NaN      True    0.503575    0.498759    0.503507      0.498759  \n",
       "76            NaN      True    0.614388    0.624069    0.613766      0.624069  \n",
       "85            NaN     False    0.619465    0.640819    0.619465      0.640819  \n",
       "89            NaN     False    0.610478    0.650124    0.610478      0.650124  \n",
       "92            NaN      True    0.614643    0.638337    0.614643      0.638337  \n",
       "94            NaN      True    0.601052    0.639578    0.601052      0.639578  \n",
       "97            NaN     False    0.613985    0.635236    0.613985      0.635236  \n",
       "100           NaN      True    0.611355    0.629032    0.611355      0.629032  \n",
       "103           NaN     False    0.614204    0.638958    0.614204      0.638958  \n",
       "106           NaN      True    0.615520    0.642060    0.615520      0.642060  \n",
       "109           NaN     False    0.620123    0.638337    0.620123      0.638337  \n",
       "112           NaN      True    0.614862    0.641439    0.614862      0.641439  \n",
       "295          2.23     False    0.610697    0.641439    0.610697      0.641439  \n",
       "297          2.25     False    0.627795    0.649504    0.627795      0.649504  \n",
       "299          2.31     False    0.616177    0.644541    0.616177      0.644541  \n",
       "301          2.37     False    0.621000    0.653846    0.621000      0.653846  \n",
       "303          2.43     False    0.615520    0.643300    0.615520      0.643300  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "%-------------------- vasr --------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19, 15)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\"></th>\n",
       "      <th>val</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\"></th>\n",
       "      <th>relation-model</th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th></th>\n",
       "      <th>vasr</th>\n",
       "      <th>vasr</th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th>vasr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>wandb_urls</th>\n",
       "      <th>id</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>class</th>\n",
       "      <th>img_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>based_on</th>\n",
       "      <th>finetune_from</th>\n",
       "      <th>is_double</th>\n",
       "      <th>vasr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>fe8alk5s</td>\n",
       "      <td>2.10</td>\n",
       "      <td>vasr_scoring_esnb</td>\n",
       "      <td>relation_esnb_single</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>1.273663</td>\n",
       "      <td>0.560199</td>\n",
       "      <td>0.392536</td>\n",
       "      <td>0.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.388606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>a1djj3cf</td>\n",
       "      <td>2.12</td>\n",
       "      <td>vaec_vasr_scoring_esnb</td>\n",
       "      <td>relation_esnb_dual</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1.386482</td>\n",
       "      <td>0.249298</td>\n",
       "      <td>0.251667</td>\n",
       "      <td>0.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.251667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>hxi02x0k</td>\n",
       "      <td>2.13</td>\n",
       "      <td>vaec_vasr_scoring_esnb</td>\n",
       "      <td>relation_esnb_dual</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.386459</td>\n",
       "      <td>0.249298</td>\n",
       "      <td>0.251667</td>\n",
       "      <td>0.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.251667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>czzd7aig</td>\n",
       "      <td>2.14</td>\n",
       "      <td>vaec_vasr_scoring_esnb_vit</td>\n",
       "      <td>relation_esnb_dual</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1.296681</td>\n",
       "      <td>0.311873</td>\n",
       "      <td>0.303448</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.308448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>31davcan</td>\n",
       "      <td>2.18</td>\n",
       "      <td>vasr_scoring_esnb-2</td>\n",
       "      <td>relation_esnb_single_2</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>1.242051</td>\n",
       "      <td>0.881502</td>\n",
       "      <td>0.402501</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.393305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>zcs5hpdx</td>\n",
       "      <td>2.22</td>\n",
       "      <td>vasr_scoring_esnb-2_larger</td>\n",
       "      <td>relation_esnb_single_2</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>466</td>\n",
       "      <td>1.251527</td>\n",
       "      <td>0.995999</td>\n",
       "      <td>0.400776</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.385082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>otzj3e5r</td>\n",
       "      <td>2.24</td>\n",
       "      <td>vaec_vasr_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnb_dual_2</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>1.359995</td>\n",
       "      <td>0.613656</td>\n",
       "      <td>0.363405</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.314032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>8rnyacfx</td>\n",
       "      <td>2.26</td>\n",
       "      <td>vaec_vasr_scoring_esnb_vit-2_larger</td>\n",
       "      <td>relation_esnb_dual_2</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>247</td>\n",
       "      <td>1.364500</td>\n",
       "      <td>0.685975</td>\n",
       "      <td>0.342121</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.310219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>7qqlk8cf</td>\n",
       "      <td>2.30</td>\n",
       "      <td>vasr_scoring_esnb-2</td>\n",
       "      <td>relation_esnbv2_single</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>216</td>\n",
       "      <td>1.253275</td>\n",
       "      <td>0.471844</td>\n",
       "      <td>0.398088</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.380388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>zbtfqra0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>vaec_vasr_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnbv2_dual</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>112</td>\n",
       "      <td>1.262369</td>\n",
       "      <td>0.404882</td>\n",
       "      <td>0.404754</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.353573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>t2r6zt8v</td>\n",
       "      <td>2.36</td>\n",
       "      <td>vasr_scoring_esnb-2</td>\n",
       "      <td>relation_esnbv2_single-lower_lr</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>216</td>\n",
       "      <td>1.252419</td>\n",
       "      <td>0.444127</td>\n",
       "      <td>0.388706</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.382457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>q3dytac4</td>\n",
       "      <td>2.38</td>\n",
       "      <td>vaec_vasr_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnbv2_dual-lower_lr</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>112</td>\n",
       "      <td>1.276350</td>\n",
       "      <td>0.396791</td>\n",
       "      <td>0.386664</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.352150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>fn7nz09e</td>\n",
       "      <td>2.42</td>\n",
       "      <td>vasr_scoring_esnb-2</td>\n",
       "      <td>relation_esnbv2_single-smaller_scoring</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>1.252190</td>\n",
       "      <td>0.514170</td>\n",
       "      <td>0.395654</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.383923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2icetmy9</td>\n",
       "      <td>2.44</td>\n",
       "      <td>vaec_vasr_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnbv2_dual-smaller_scoring</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>404</td>\n",
       "      <td>1.277913</td>\n",
       "      <td>0.550970</td>\n",
       "      <td>0.399176</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>6x73b2yi</td>\n",
       "      <td>2.56</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>202</td>\n",
       "      <td>1.244115</td>\n",
       "      <td>0.614587</td>\n",
       "      <td>0.400137</td>\n",
       "      <td>None</td>\n",
       "      <td>2.24</td>\n",
       "      <td>False</td>\n",
       "      <td>0.397262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>e99tblm8</td>\n",
       "      <td>2.58</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>58</td>\n",
       "      <td>1.311395</td>\n",
       "      <td>0.448818</td>\n",
       "      <td>0.356316</td>\n",
       "      <td>None</td>\n",
       "      <td>2.26</td>\n",
       "      <td>False</td>\n",
       "      <td>0.350482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>z9o1y4ak</td>\n",
       "      <td>2.60</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>30</td>\n",
       "      <td>1.248005</td>\n",
       "      <td>0.381553</td>\n",
       "      <td>0.391056</td>\n",
       "      <td>None</td>\n",
       "      <td>2.32</td>\n",
       "      <td>False</td>\n",
       "      <td>0.389708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>7didjvnu</td>\n",
       "      <td>2.62</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>30</td>\n",
       "      <td>1.260576</td>\n",
       "      <td>0.377375</td>\n",
       "      <td>0.384196</td>\n",
       "      <td>None</td>\n",
       "      <td>2.38</td>\n",
       "      <td>False</td>\n",
       "      <td>0.384196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>j99q3y1j</td>\n",
       "      <td>2.64</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>97</td>\n",
       "      <td>1.256692</td>\n",
       "      <td>0.423685</td>\n",
       "      <td>0.393510</td>\n",
       "      <td>None</td>\n",
       "      <td>2.44</td>\n",
       "      <td>False</td>\n",
       "      <td>0.385825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           \\\n",
       "                                                            \n",
       "    wandb_urls    id                        experiment_nm   \n",
       "79    fe8alk5s  2.10                    vasr_scoring_esnb   \n",
       "81    a1djj3cf  2.12               vaec_vasr_scoring_esnb   \n",
       "82    hxi02x0k  2.13               vaec_vasr_scoring_esnb   \n",
       "83    czzd7aig  2.14           vaec_vasr_scoring_esnb_vit   \n",
       "87    31davcan  2.18                  vasr_scoring_esnb-2   \n",
       "91    zcs5hpdx  2.22           vasr_scoring_esnb-2_larger   \n",
       "93    otzj3e5r  2.24         vaec_vasr_scoring_esnb_vit-2   \n",
       "95    8rnyacfx  2.26  vaec_vasr_scoring_esnb_vit-2_larger   \n",
       "99    7qqlk8cf  2.30                  vasr_scoring_esnb-2   \n",
       "101   zbtfqra0  2.32         vaec_vasr_scoring_esnb_vit-2   \n",
       "105   t2r6zt8v  2.36                  vasr_scoring_esnb-2   \n",
       "107   q3dytac4  2.38         vaec_vasr_scoring_esnb_vit-2   \n",
       "111   fn7nz09e  2.42                  vasr_scoring_esnb-2   \n",
       "113   2icetmy9  2.44         vaec_vasr_scoring_esnb_vit-2   \n",
       "305   6x73b2yi  2.56                             finetune   \n",
       "307   e99tblm8  2.58                             finetune   \n",
       "309   z9o1y4ak  2.60                             finetune   \n",
       "311   7didjvnu  2.62                             finetune   \n",
       "313   j99q3y1j  2.64                             finetune   \n",
       "\n",
       "                                                                     \\\n",
       "                                            relation-model            \n",
       "                                    test_nm          class img_size   \n",
       "79                     relation_esnb_single           ESNB       80   \n",
       "81                       relation_esnb_dual           ESNB       80   \n",
       "82                       relation_esnb_dual           ESNB       80   \n",
       "83                       relation_esnb_dual           ESNB       80   \n",
       "87                   relation_esnb_single_2           ESNB       80   \n",
       "91                   relation_esnb_single_2           ESNB       80   \n",
       "93                     relation_esnb_dual_2           ESNB       80   \n",
       "95                     relation_esnb_dual_2           ESNB       80   \n",
       "99                   relation_esnbv2_single         ESNBv2       80   \n",
       "101                    relation_esnbv2_dual         ESNBv2       80   \n",
       "105         relation_esnbv2_single-lower_lr         ESNBv2       80   \n",
       "107           relation_esnbv2_dual-lower_lr         ESNBv2       80   \n",
       "111  relation_esnbv2_single-smaller_scoring         ESNBv2       80   \n",
       "113    relation_esnbv2_dual-smaller_scoring         ESNBv2       80   \n",
       "305   finetune_on_single_task_based_on_dual           ESNB       80   \n",
       "307   finetune_on_single_task_based_on_dual           ESNB       80   \n",
       "309   finetune_on_single_task_based_on_dual         ESNBv2       80   \n",
       "311   finetune_on_single_task_based_on_dual         ESNBv2       80   \n",
       "313   finetune_on_single_task_based_on_dual         ESNBv2       80   \n",
       "\n",
       "                               val     train       val                         \\\n",
       "                                        vasr      vasr                          \n",
       "    batch_size max_epoch      loss  accuracy  accuracy based_on finetune_from   \n",
       "79          32        50  1.273663  0.560199  0.392536     0.31           NaN   \n",
       "81           8         2  1.386482  0.249298  0.251667     0.30           NaN   \n",
       "82           8         1  1.386459  0.249298  0.251667     0.31           NaN   \n",
       "83           8         4  1.296681  0.311873  0.303448     None           NaN   \n",
       "87         256       499  1.242051  0.881502  0.402501     None           NaN   \n",
       "91         128       466  1.251527  0.995999  0.400776     None           NaN   \n",
       "93         256       499  1.359995  0.613656  0.363405     None           NaN   \n",
       "95         128       247  1.364500  0.685975  0.342121     None           NaN   \n",
       "99         256       216  1.253275  0.471844  0.398088     None           NaN   \n",
       "101        256       112  1.262369  0.404882  0.404754     None           NaN   \n",
       "105        256       216  1.252419  0.444127  0.388706     None           NaN   \n",
       "107        256       112  1.276350  0.396791  0.386664     None           NaN   \n",
       "111        256       499  1.252190  0.514170  0.395654     None           NaN   \n",
       "113        256       404  1.277913  0.550970  0.399176     None           NaN   \n",
       "305        256       202  1.244115  0.614587  0.400137     None          2.24   \n",
       "307        128        58  1.311395  0.448818  0.356316     None          2.26   \n",
       "309        256        30  1.248005  0.381553  0.391056     None          2.32   \n",
       "311        256        30  1.260576  0.377375  0.384196     None          2.38   \n",
       "313        256        97  1.256692  0.423685  0.393510     None          2.44   \n",
       "\n",
       "                   test  \n",
       "                   vasr  \n",
       "    is_double      vasr  \n",
       "79      False  0.388606  \n",
       "81       True  0.251667  \n",
       "82       True  0.251667  \n",
       "83       True  0.308448  \n",
       "87      False  0.393305  \n",
       "91      False  0.385082  \n",
       "93       True  0.314032  \n",
       "95       True  0.310219  \n",
       "99      False  0.380388  \n",
       "101      True  0.353573  \n",
       "105     False  0.382457  \n",
       "107      True  0.352150  \n",
       "111     False  0.383923  \n",
       "113      True       NaN  \n",
       "305     False  0.397262  \n",
       "307     False  0.350482  \n",
       "309     False  0.389708  \n",
       "311     False  0.384196  \n",
       "313     False  0.385825  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "%-------------------- bongard_logo --------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21, 18)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\"></th>\n",
       "      <th>val</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th colspan=\"4\" halign=\"left\">test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\"></th>\n",
       "      <th>relation-model</th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th></th>\n",
       "      <th>bongard_logo</th>\n",
       "      <th>bongard_logo</th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th colspan=\"4\" halign=\"left\">bongard_logo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>wandb_urls</th>\n",
       "      <th>id</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>class</th>\n",
       "      <th>img_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>based_on</th>\n",
       "      <th>finetune_from</th>\n",
       "      <th>is_double</th>\n",
       "      <th>test_bd</th>\n",
       "      <th>test_ff</th>\n",
       "      <th>test_hd_comb</th>\n",
       "      <th>test_hd_novel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>sww31yqe</td>\n",
       "      <td>2.1</td>\n",
       "      <td>bongard_logo_scoring_esnb</td>\n",
       "      <td>relation_esnb_single</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>64</td>\n",
       "      <td>242</td>\n",
       "      <td>0.691456</td>\n",
       "      <td>0.514409</td>\n",
       "      <td>0.547778</td>\n",
       "      <td>0.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.4550</td>\n",
       "      <td>0.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>vlann6y8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>bongard_logo_scoring_esnb</td>\n",
       "      <td>relation_esnb_single</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>67</td>\n",
       "      <td>1.382411</td>\n",
       "      <td>0.515161</td>\n",
       "      <td>0.524444</td>\n",
       "      <td>0.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.5425</td>\n",
       "      <td>0.565625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>oxnqsd2g</td>\n",
       "      <td>2.4</td>\n",
       "      <td>bongard_logo_scoring_esnb_vit</td>\n",
       "      <td>relation_esnb_single</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>292</td>\n",
       "      <td>0.662764</td>\n",
       "      <td>0.600430</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.585417</td>\n",
       "      <td>0.556667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>o0oz8bt5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>bongard_logo_hoi_scoring_esnb</td>\n",
       "      <td>relation_esnb_dual</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>0.692726</td>\n",
       "      <td>0.507335</td>\n",
       "      <td>0.525556</td>\n",
       "      <td>0.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.487500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>h78u70gc</td>\n",
       "      <td>2.6</td>\n",
       "      <td>bongard_logo_hoi_scoring_esnb</td>\n",
       "      <td>relation_esnb_dual</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.692724</td>\n",
       "      <td>0.507335</td>\n",
       "      <td>0.525556</td>\n",
       "      <td>0.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.487500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>tiji5vvm</td>\n",
       "      <td>2.7</td>\n",
       "      <td>bongard_logo_hoi_scoring_esnb_vit</td>\n",
       "      <td>relation_esnb_dual</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>0.632098</td>\n",
       "      <td>0.579153</td>\n",
       "      <td>0.587778</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.528333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>pr40wcrl</td>\n",
       "      <td>2.15</td>\n",
       "      <td>bongard_logo_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnb_single_2</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>499</td>\n",
       "      <td>0.670173</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.567778</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.554167</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.5275</td>\n",
       "      <td>0.509375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>uzfrln08</td>\n",
       "      <td>2.19</td>\n",
       "      <td>bongard_logo_scoring_esnb_vit-2_larger</td>\n",
       "      <td>relation_esnb_single_2</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>499</td>\n",
       "      <td>0.670486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.562222</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>0.5325</td>\n",
       "      <td>0.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>7byrc875</td>\n",
       "      <td>2.23</td>\n",
       "      <td>bongard_logo_hoi_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnb_dual_2</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>0.652056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.576667</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.518333</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>8cjb18ld</td>\n",
       "      <td>2.25</td>\n",
       "      <td>bongard_logo_hoi_scoring_esnb_vit-2_larger</td>\n",
       "      <td>relation_esnb_dual_2</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>499</td>\n",
       "      <td>0.644687</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.547917</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.5025</td>\n",
       "      <td>0.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>uwxnf04f</td>\n",
       "      <td>2.27</td>\n",
       "      <td>bongard_logo_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnbv2_single</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>499</td>\n",
       "      <td>0.662450</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.582222</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>bzd3toty</td>\n",
       "      <td>2.31</td>\n",
       "      <td>bongard_logo_hoi_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnbv2_dual</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>0.653035</td>\n",
       "      <td>0.999826</td>\n",
       "      <td>0.587778</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.4825</td>\n",
       "      <td>0.540625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>cgsz3fpe</td>\n",
       "      <td>2.33</td>\n",
       "      <td>bongard_logo_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnbv2_single-lower_lr</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>499</td>\n",
       "      <td>0.667406</td>\n",
       "      <td>0.998280</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.543750</td>\n",
       "      <td>0.526667</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.521875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>17cweqpi</td>\n",
       "      <td>2.37</td>\n",
       "      <td>bongard_logo_hoi_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnbv2_dual-lower_lr</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>0.657176</td>\n",
       "      <td>0.999477</td>\n",
       "      <td>0.575556</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2nfr7u4t</td>\n",
       "      <td>2.39</td>\n",
       "      <td>bongard_logo_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnbv2_single-smaller_scoring</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>499</td>\n",
       "      <td>0.661460</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.535417</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.5550</td>\n",
       "      <td>0.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>15masdov</td>\n",
       "      <td>2.43</td>\n",
       "      <td>bongard_logo_hoi_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnbv2_dual-smaller_scoring</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>0.648287</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>0.592222</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.529167</td>\n",
       "      <td>0.528333</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>i0ioe24x</td>\n",
       "      <td>2.45</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>0.677954</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>None</td>\n",
       "      <td>2.23</td>\n",
       "      <td>False</td>\n",
       "      <td>0.581250</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.5275</td>\n",
       "      <td>0.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>cyr19v26</td>\n",
       "      <td>2.47</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>499</td>\n",
       "      <td>0.664118</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.563333</td>\n",
       "      <td>None</td>\n",
       "      <td>2.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.526667</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>0.509375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>5j6efvtf</td>\n",
       "      <td>2.49</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>0.676622</td>\n",
       "      <td>0.999677</td>\n",
       "      <td>0.581111</td>\n",
       "      <td>None</td>\n",
       "      <td>2.31</td>\n",
       "      <td>False</td>\n",
       "      <td>0.547917</td>\n",
       "      <td>0.538333</td>\n",
       "      <td>0.5475</td>\n",
       "      <td>0.534375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>7gjzuhmc</td>\n",
       "      <td>2.51</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>0.675765</td>\n",
       "      <td>0.998172</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>None</td>\n",
       "      <td>2.37</td>\n",
       "      <td>False</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>byiezclx</td>\n",
       "      <td>2.53</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>0.678251</td>\n",
       "      <td>0.999355</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>None</td>\n",
       "      <td>2.43</td>\n",
       "      <td>False</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>0.5275</td>\n",
       "      <td>0.534375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  \\\n",
       "                                                                   \n",
       "    wandb_urls    id                               experiment_nm   \n",
       "70    sww31yqe   2.1                   bongard_logo_scoring_esnb   \n",
       "71    vlann6y8   2.2                   bongard_logo_scoring_esnb   \n",
       "73    oxnqsd2g   2.4               bongard_logo_scoring_esnb_vit   \n",
       "74    o0oz8bt5   2.5               bongard_logo_hoi_scoring_esnb   \n",
       "75    h78u70gc   2.6               bongard_logo_hoi_scoring_esnb   \n",
       "76    tiji5vvm   2.7           bongard_logo_hoi_scoring_esnb_vit   \n",
       "84    pr40wcrl  2.15             bongard_logo_scoring_esnb_vit-2   \n",
       "88    uzfrln08  2.19      bongard_logo_scoring_esnb_vit-2_larger   \n",
       "92    7byrc875  2.23         bongard_logo_hoi_scoring_esnb_vit-2   \n",
       "94    8cjb18ld  2.25  bongard_logo_hoi_scoring_esnb_vit-2_larger   \n",
       "96    uwxnf04f  2.27             bongard_logo_scoring_esnb_vit-2   \n",
       "100   bzd3toty  2.31         bongard_logo_hoi_scoring_esnb_vit-2   \n",
       "102   cgsz3fpe  2.33             bongard_logo_scoring_esnb_vit-2   \n",
       "106   17cweqpi  2.37         bongard_logo_hoi_scoring_esnb_vit-2   \n",
       "108   2nfr7u4t  2.39             bongard_logo_scoring_esnb_vit-2   \n",
       "112   15masdov  2.43         bongard_logo_hoi_scoring_esnb_vit-2   \n",
       "294   i0ioe24x  2.45                                    finetune   \n",
       "296   cyr19v26  2.47                                    finetune   \n",
       "298   5j6efvtf  2.49                                    finetune   \n",
       "300   7gjzuhmc  2.51                                    finetune   \n",
       "302   byiezclx  2.53                                    finetune   \n",
       "\n",
       "                                                                     \\\n",
       "                                            relation-model            \n",
       "                                    test_nm          class img_size   \n",
       "70                     relation_esnb_single           ESNB       80   \n",
       "71                     relation_esnb_single           ESNB       80   \n",
       "73                     relation_esnb_single           ESNB       80   \n",
       "74                       relation_esnb_dual           ESNB       80   \n",
       "75                       relation_esnb_dual           ESNB       80   \n",
       "76                       relation_esnb_dual           ESNB       80   \n",
       "84                   relation_esnb_single_2           ESNB       80   \n",
       "88                   relation_esnb_single_2           ESNB       80   \n",
       "92                     relation_esnb_dual_2           ESNB       80   \n",
       "94                     relation_esnb_dual_2           ESNB       80   \n",
       "96                   relation_esnbv2_single         ESNBv2       80   \n",
       "100                    relation_esnbv2_dual         ESNBv2       80   \n",
       "102         relation_esnbv2_single-lower_lr         ESNBv2       80   \n",
       "106           relation_esnbv2_dual-lower_lr         ESNBv2       80   \n",
       "108  relation_esnbv2_single-smaller_scoring         ESNBv2       80   \n",
       "112    relation_esnbv2_dual-smaller_scoring         ESNBv2       80   \n",
       "294   finetune_on_single_task_based_on_dual           ESNB       80   \n",
       "296   finetune_on_single_task_based_on_dual           ESNB       80   \n",
       "298   finetune_on_single_task_based_on_dual         ESNBv2       80   \n",
       "300   finetune_on_single_task_based_on_dual         ESNBv2       80   \n",
       "302   finetune_on_single_task_based_on_dual         ESNBv2       80   \n",
       "\n",
       "                               val        train          val           \\\n",
       "                                   bongard_logo bongard_logo            \n",
       "    batch_size max_epoch      loss     accuracy     accuracy based_on   \n",
       "70          64       242  0.691456     0.514409     0.547778     0.28   \n",
       "71          16        67  1.382411     0.515161     0.524444     0.29   \n",
       "73          16       292  0.662764     0.600430     0.616667     None   \n",
       "74           8        17  0.692726     0.507335     0.525556     0.28   \n",
       "75           8        11  0.692724     0.507335     0.525556     0.29   \n",
       "76           4        17  0.632098     0.579153     0.587778     None   \n",
       "84         128       499  0.670173     1.000000     0.567778     None   \n",
       "88         128       499  0.670486     1.000000     0.562222     None   \n",
       "92         256       499  0.652056     1.000000     0.576667     None   \n",
       "94         128       499  0.644687     1.000000     0.573333     None   \n",
       "96         128       499  0.662450     0.999892     0.582222     None   \n",
       "100        256       499  0.653035     0.999826     0.587778     None   \n",
       "102        128       499  0.667406     0.998280     0.570000     None   \n",
       "106        256       499  0.657176     0.999477     0.575556     None   \n",
       "108        128       499  0.661460     1.000000     0.577778     None   \n",
       "112        256       499  0.648287     0.999869     0.592222     None   \n",
       "294        256       499  0.677954     1.000000     0.572222     None   \n",
       "296        128       499  0.664118     1.000000     0.563333     None   \n",
       "298        256       499  0.676622     0.999677     0.581111     None   \n",
       "300        256       499  0.675765     0.998172     0.590000     None   \n",
       "302        256       499  0.678251     0.999355     0.588889     None   \n",
       "\n",
       "                                    test                                       \n",
       "                            bongard_logo                                       \n",
       "    finetune_from is_double      test_bd   test_ff test_hd_comb test_hd_novel  \n",
       "70            NaN     False     0.458333  0.485000       0.4550      0.453125  \n",
       "71            NaN     False     0.531250  0.533333       0.5425      0.565625  \n",
       "73            NaN     False     0.585417  0.556667          NaN           NaN  \n",
       "74            NaN      True     0.483333  0.490000       0.5000      0.487500  \n",
       "75            NaN      True     0.483333  0.490000       0.5000      0.487500  \n",
       "76            NaN      True     0.583333  0.528333          NaN           NaN  \n",
       "84            NaN     False     0.554167  0.525000       0.5275      0.509375  \n",
       "88            NaN     False     0.525000  0.505000       0.5325      0.537500  \n",
       "92            NaN      True     0.541667  0.518333       0.5075      0.531250  \n",
       "94            NaN      True     0.547917  0.495000       0.5025      0.512500  \n",
       "96            NaN     False     0.525000  0.516667       0.5250      0.531250  \n",
       "100           NaN      True     0.525000  0.520000       0.4825      0.540625  \n",
       "102           NaN     False     0.543750  0.526667       0.5500      0.521875  \n",
       "106           NaN      True     0.541667  0.500000       0.4975      0.525000  \n",
       "108           NaN     False     0.535417  0.530000       0.5550      0.537500  \n",
       "112           NaN      True     0.529167  0.528333       0.4900      0.537500  \n",
       "294          2.23     False     0.581250  0.566667       0.5275      0.525000  \n",
       "296          2.25     False     0.545833  0.526667       0.5100      0.509375  \n",
       "298          2.31     False     0.547917  0.538333       0.5475      0.534375  \n",
       "300          2.37     False     0.552083  0.533333       0.5075      0.546875  \n",
       "302          2.43     False     0.566667  0.535000       0.5275      0.534375  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "%-------------------- vaec --------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21, 19)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\"></th>\n",
       "      <th>val</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th colspan=\"5\" halign=\"left\">test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\"></th>\n",
       "      <th>relation-model</th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th></th>\n",
       "      <th>vaec</th>\n",
       "      <th>vaec</th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th colspan=\"5\" halign=\"left\">vaec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>wandb_urls</th>\n",
       "      <th>id</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>class</th>\n",
       "      <th>img_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>based_on</th>\n",
       "      <th>finetune_from</th>\n",
       "      <th>is_double</th>\n",
       "      <th>test1</th>\n",
       "      <th>test2</th>\n",
       "      <th>test3</th>\n",
       "      <th>test4</th>\n",
       "      <th>test5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>4n0uo41y</td>\n",
       "      <td>2.8</td>\n",
       "      <td>vaec_scoring_esnb</td>\n",
       "      <td>relation_esnb_single</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>241</td>\n",
       "      <td>1.386155</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6dn8ptmm</td>\n",
       "      <td>2.9</td>\n",
       "      <td>vaec_scoring_esnb</td>\n",
       "      <td>relation_esnb_single</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>64</td>\n",
       "      <td>114</td>\n",
       "      <td>1.386141</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0nro4dv2</td>\n",
       "      <td>2.11</td>\n",
       "      <td>vaec_scoring_esnb_vit</td>\n",
       "      <td>relation_esnb_single</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>32</td>\n",
       "      <td>184</td>\n",
       "      <td>1.325842</td>\n",
       "      <td>0.409716</td>\n",
       "      <td>0.355444</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.349079</td>\n",
       "      <td>0.363990</td>\n",
       "      <td>0.372575</td>\n",
       "      <td>0.327783</td>\n",
       "      <td>0.350652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>a1djj3cf</td>\n",
       "      <td>2.12</td>\n",
       "      <td>vaec_vasr_scoring_esnb</td>\n",
       "      <td>relation_esnb_dual</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1.386482</td>\n",
       "      <td>0.250961</td>\n",
       "      <td>0.251436</td>\n",
       "      <td>0.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.248004</td>\n",
       "      <td>0.248004</td>\n",
       "      <td>0.248004</td>\n",
       "      <td>0.248004</td>\n",
       "      <td>0.248004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>hxi02x0k</td>\n",
       "      <td>2.13</td>\n",
       "      <td>vaec_vasr_scoring_esnb</td>\n",
       "      <td>relation_esnb_dual</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.386459</td>\n",
       "      <td>0.250099</td>\n",
       "      <td>0.249055</td>\n",
       "      <td>0.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.248004</td>\n",
       "      <td>0.248004</td>\n",
       "      <td>0.248004</td>\n",
       "      <td>0.248004</td>\n",
       "      <td>0.248004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>czzd7aig</td>\n",
       "      <td>2.14</td>\n",
       "      <td>vaec_vasr_scoring_esnb_vit</td>\n",
       "      <td>relation_esnb_dual</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1.296681</td>\n",
       "      <td>0.358044</td>\n",
       "      <td>0.317806</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.327078</td>\n",
       "      <td>0.345233</td>\n",
       "      <td>0.353190</td>\n",
       "      <td>0.295858</td>\n",
       "      <td>0.332302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1wkm9t3h</td>\n",
       "      <td>2.17</td>\n",
       "      <td>vaec_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnb_single_2</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>1.351307</td>\n",
       "      <td>0.486506</td>\n",
       "      <td>0.338746</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.329561</td>\n",
       "      <td>0.350889</td>\n",
       "      <td>0.354054</td>\n",
       "      <td>0.313285</td>\n",
       "      <td>0.327514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>jv838pmq</td>\n",
       "      <td>2.21</td>\n",
       "      <td>vaec_scoring_esnb_vit-2_larger</td>\n",
       "      <td>relation_esnb_single_2</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>499</td>\n",
       "      <td>1.345836</td>\n",
       "      <td>0.515943</td>\n",
       "      <td>0.340341</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.334213</td>\n",
       "      <td>0.346016</td>\n",
       "      <td>0.352910</td>\n",
       "      <td>0.317908</td>\n",
       "      <td>0.333380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>otzj3e5r</td>\n",
       "      <td>2.24</td>\n",
       "      <td>vaec_vasr_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnb_dual_2</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>1.359995</td>\n",
       "      <td>0.995102</td>\n",
       "      <td>0.354361</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.323634</td>\n",
       "      <td>0.340901</td>\n",
       "      <td>0.349347</td>\n",
       "      <td>0.305115</td>\n",
       "      <td>0.325914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>8rnyacfx</td>\n",
       "      <td>2.26</td>\n",
       "      <td>vaec_vasr_scoring_esnb_vit-2_larger</td>\n",
       "      <td>relation_esnb_dual_2</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>247</td>\n",
       "      <td>1.364500</td>\n",
       "      <td>0.967145</td>\n",
       "      <td>0.356744</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.323791</td>\n",
       "      <td>0.345167</td>\n",
       "      <td>0.341343</td>\n",
       "      <td>0.307002</td>\n",
       "      <td>0.329916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4k1zs29y</td>\n",
       "      <td>2.29</td>\n",
       "      <td>vaec_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnbv2_single</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>1.222424</td>\n",
       "      <td>0.753042</td>\n",
       "      <td>0.456343</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.439888</td>\n",
       "      <td>0.453008</td>\n",
       "      <td>0.458799</td>\n",
       "      <td>0.426579</td>\n",
       "      <td>0.454434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>zbtfqra0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>vaec_vasr_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnbv2_dual</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>112</td>\n",
       "      <td>1.262369</td>\n",
       "      <td>0.918630</td>\n",
       "      <td>0.464097</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.416773</td>\n",
       "      <td>0.435819</td>\n",
       "      <td>0.447173</td>\n",
       "      <td>0.410693</td>\n",
       "      <td>0.444742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>f35atrpj</td>\n",
       "      <td>2.35</td>\n",
       "      <td>vaec_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnbv2_single-lower_lr</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>1.244735</td>\n",
       "      <td>0.745422</td>\n",
       "      <td>0.447302</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.418535</td>\n",
       "      <td>0.421988</td>\n",
       "      <td>0.435688</td>\n",
       "      <td>0.401679</td>\n",
       "      <td>0.432453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>q3dytac4</td>\n",
       "      <td>2.38</td>\n",
       "      <td>vaec_vasr_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnbv2_dual-lower_lr</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>112</td>\n",
       "      <td>1.276350</td>\n",
       "      <td>0.863958</td>\n",
       "      <td>0.448634</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.416778</td>\n",
       "      <td>0.439037</td>\n",
       "      <td>0.443787</td>\n",
       "      <td>0.411176</td>\n",
       "      <td>0.441873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>cfun01uk</td>\n",
       "      <td>2.41</td>\n",
       "      <td>vaec_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnbv2_single-smaller_scoring</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>1.259065</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.454768</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.421260</td>\n",
       "      <td>0.429235</td>\n",
       "      <td>0.433597</td>\n",
       "      <td>0.401738</td>\n",
       "      <td>0.434281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2icetmy9</td>\n",
       "      <td>2.44</td>\n",
       "      <td>vaec_vasr_scoring_esnb_vit-2</td>\n",
       "      <td>relation_esnbv2_dual-smaller_scoring</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>404</td>\n",
       "      <td>1.277913</td>\n",
       "      <td>0.972908</td>\n",
       "      <td>0.467656</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.389893</td>\n",
       "      <td>0.406063</td>\n",
       "      <td>0.413788</td>\n",
       "      <td>0.380852</td>\n",
       "      <td>0.408209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>2gl18gak</td>\n",
       "      <td>2.55</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>1.350076</td>\n",
       "      <td>0.488044</td>\n",
       "      <td>0.341475</td>\n",
       "      <td>None</td>\n",
       "      <td>2.24</td>\n",
       "      <td>False</td>\n",
       "      <td>0.331078</td>\n",
       "      <td>0.353624</td>\n",
       "      <td>0.361482</td>\n",
       "      <td>0.315887</td>\n",
       "      <td>0.334603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>vx5w0394</td>\n",
       "      <td>2.57</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>ESNB</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>499</td>\n",
       "      <td>1.351820</td>\n",
       "      <td>0.511453</td>\n",
       "      <td>0.339488</td>\n",
       "      <td>None</td>\n",
       "      <td>2.26</td>\n",
       "      <td>False</td>\n",
       "      <td>0.336959</td>\n",
       "      <td>0.356277</td>\n",
       "      <td>0.360170</td>\n",
       "      <td>0.321138</td>\n",
       "      <td>0.338002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>ze6z8k3n</td>\n",
       "      <td>2.59</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>450</td>\n",
       "      <td>1.228440</td>\n",
       "      <td>0.753464</td>\n",
       "      <td>0.457647</td>\n",
       "      <td>None</td>\n",
       "      <td>2.32</td>\n",
       "      <td>False</td>\n",
       "      <td>0.445302</td>\n",
       "      <td>0.462918</td>\n",
       "      <td>0.463110</td>\n",
       "      <td>0.431871</td>\n",
       "      <td>0.457291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>u4dvtx3f</td>\n",
       "      <td>2.61</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>456</td>\n",
       "      <td>1.257242</td>\n",
       "      <td>0.746979</td>\n",
       "      <td>0.449978</td>\n",
       "      <td>None</td>\n",
       "      <td>2.38</td>\n",
       "      <td>False</td>\n",
       "      <td>0.428901</td>\n",
       "      <td>0.445546</td>\n",
       "      <td>0.452186</td>\n",
       "      <td>0.416755</td>\n",
       "      <td>0.449373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>4yjjb05k</td>\n",
       "      <td>2.63</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>ESNBv2</td>\n",
       "      <td>80</td>\n",
       "      <td>256</td>\n",
       "      <td>499</td>\n",
       "      <td>1.258883</td>\n",
       "      <td>0.713635</td>\n",
       "      <td>0.451716</td>\n",
       "      <td>None</td>\n",
       "      <td>2.44</td>\n",
       "      <td>False</td>\n",
       "      <td>0.413905</td>\n",
       "      <td>0.427170</td>\n",
       "      <td>0.432077</td>\n",
       "      <td>0.403918</td>\n",
       "      <td>0.424123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           \\\n",
       "                                                            \n",
       "    wandb_urls    id                        experiment_nm   \n",
       "77    4n0uo41y   2.8                    vaec_scoring_esnb   \n",
       "78    6dn8ptmm   2.9                    vaec_scoring_esnb   \n",
       "80    0nro4dv2  2.11                vaec_scoring_esnb_vit   \n",
       "81    a1djj3cf  2.12               vaec_vasr_scoring_esnb   \n",
       "82    hxi02x0k  2.13               vaec_vasr_scoring_esnb   \n",
       "83    czzd7aig  2.14           vaec_vasr_scoring_esnb_vit   \n",
       "86    1wkm9t3h  2.17              vaec_scoring_esnb_vit-2   \n",
       "90    jv838pmq  2.21       vaec_scoring_esnb_vit-2_larger   \n",
       "93    otzj3e5r  2.24         vaec_vasr_scoring_esnb_vit-2   \n",
       "95    8rnyacfx  2.26  vaec_vasr_scoring_esnb_vit-2_larger   \n",
       "98    4k1zs29y  2.29              vaec_scoring_esnb_vit-2   \n",
       "101   zbtfqra0  2.32         vaec_vasr_scoring_esnb_vit-2   \n",
       "104   f35atrpj  2.35              vaec_scoring_esnb_vit-2   \n",
       "107   q3dytac4  2.38         vaec_vasr_scoring_esnb_vit-2   \n",
       "110   cfun01uk  2.41              vaec_scoring_esnb_vit-2   \n",
       "113   2icetmy9  2.44         vaec_vasr_scoring_esnb_vit-2   \n",
       "304   2gl18gak  2.55                             finetune   \n",
       "306   vx5w0394  2.57                             finetune   \n",
       "308   ze6z8k3n  2.59                             finetune   \n",
       "310   u4dvtx3f  2.61                             finetune   \n",
       "312   4yjjb05k  2.63                             finetune   \n",
       "\n",
       "                                                                     \\\n",
       "                                            relation-model            \n",
       "                                    test_nm          class img_size   \n",
       "77                     relation_esnb_single           ESNB       80   \n",
       "78                     relation_esnb_single           ESNB       80   \n",
       "80                     relation_esnb_single           ESNB       80   \n",
       "81                       relation_esnb_dual           ESNB       80   \n",
       "82                       relation_esnb_dual           ESNB       80   \n",
       "83                       relation_esnb_dual           ESNB       80   \n",
       "86                   relation_esnb_single_2           ESNB       80   \n",
       "90                   relation_esnb_single_2           ESNB       80   \n",
       "93                     relation_esnb_dual_2           ESNB       80   \n",
       "95                     relation_esnb_dual_2           ESNB       80   \n",
       "98                   relation_esnbv2_single         ESNBv2       80   \n",
       "101                    relation_esnbv2_dual         ESNBv2       80   \n",
       "104         relation_esnbv2_single-lower_lr         ESNBv2       80   \n",
       "107           relation_esnbv2_dual-lower_lr         ESNBv2       80   \n",
       "110  relation_esnbv2_single-smaller_scoring         ESNBv2       80   \n",
       "113    relation_esnbv2_dual-smaller_scoring         ESNBv2       80   \n",
       "304   finetune_on_single_task_based_on_dual           ESNB       80   \n",
       "306   finetune_on_single_task_based_on_dual           ESNB       80   \n",
       "308   finetune_on_single_task_based_on_dual         ESNBv2       80   \n",
       "310   finetune_on_single_task_based_on_dual         ESNBv2       80   \n",
       "312   finetune_on_single_task_based_on_dual         ESNBv2       80   \n",
       "\n",
       "                               val     train       val                         \\\n",
       "                                        vaec      vaec                          \n",
       "    batch_size max_epoch      loss  accuracy  accuracy based_on finetune_from   \n",
       "77         128       241  1.386155  0.250000  0.250000     0.30           NaN   \n",
       "78          64       114  1.386141  0.250000  0.250000     0.31           NaN   \n",
       "80          32       184  1.325842  0.409716  0.355444     None           NaN   \n",
       "81           8         2  1.386482  0.250961  0.251436     0.30           NaN   \n",
       "82           8         1  1.386459  0.250099  0.249055     0.31           NaN   \n",
       "83           8         4  1.296681  0.358044  0.317806     None           NaN   \n",
       "86         256       499  1.351307  0.486506  0.338746     None           NaN   \n",
       "90         128       499  1.345836  0.515943  0.340341     None           NaN   \n",
       "93         256       499  1.359995  0.995102  0.354361     None           NaN   \n",
       "95         128       247  1.364500  0.967145  0.356744     None           NaN   \n",
       "98         256       499  1.222424  0.753042  0.456343     None           NaN   \n",
       "101        256       112  1.262369  0.918630  0.464097     None           NaN   \n",
       "104        256       499  1.244735  0.745422  0.447302     None           NaN   \n",
       "107        256       112  1.276350  0.863958  0.448634     None           NaN   \n",
       "110        256       499  1.259065  0.713183  0.454768     None           NaN   \n",
       "113        256       404  1.277913  0.972908  0.467656     None           NaN   \n",
       "304        256       499  1.350076  0.488044  0.341475     None          2.24   \n",
       "306        128       499  1.351820  0.511453  0.339488     None          2.26   \n",
       "308        256       450  1.228440  0.753464  0.457647     None          2.32   \n",
       "310        256       456  1.257242  0.746979  0.449978     None          2.38   \n",
       "312        256       499  1.258883  0.713635  0.451716     None          2.44   \n",
       "\n",
       "                   test                                          \n",
       "                   vaec                                          \n",
       "    is_double     test1     test2     test3     test4     test5  \n",
       "77      False  0.250000  0.250000  0.250000  0.250000  0.250000  \n",
       "78      False  0.250000  0.250000  0.250000  0.250000  0.250000  \n",
       "80      False  0.349079  0.363990  0.372575  0.327783  0.350652  \n",
       "81       True  0.248004  0.248004  0.248004  0.248004  0.248004  \n",
       "82       True  0.248004  0.248004  0.248004  0.248004  0.248004  \n",
       "83       True  0.327078  0.345233  0.353190  0.295858  0.332302  \n",
       "86      False  0.329561  0.350889  0.354054  0.313285  0.327514  \n",
       "90      False  0.334213  0.346016  0.352910  0.317908  0.333380  \n",
       "93       True  0.323634  0.340901  0.349347  0.305115  0.325914  \n",
       "95       True  0.323791  0.345167  0.341343  0.307002  0.329916  \n",
       "98      False  0.439888  0.453008  0.458799  0.426579  0.454434  \n",
       "101      True  0.416773  0.435819  0.447173  0.410693  0.444742  \n",
       "104     False  0.418535  0.421988  0.435688  0.401679  0.432453  \n",
       "107      True  0.416778  0.439037  0.443787  0.411176  0.441873  \n",
       "110     False  0.421260  0.429235  0.433597  0.401738  0.434281  \n",
       "113      True  0.389893  0.406063  0.413788  0.380852  0.408209  \n",
       "304     False  0.331078  0.353624  0.361482  0.315887  0.334603  \n",
       "306     False  0.336959  0.356277  0.360170  0.321138  0.338002  \n",
       "308     False  0.445302  0.462918  0.463110  0.431871  0.457291  \n",
       "310     False  0.428901  0.445546  0.452186  0.416755  0.449373  \n",
       "312     False  0.413905  0.427170  0.432077  0.403918  0.424123  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dataset in sdatasets:\n",
    "    cols = [\n",
    "        \"wandb_urls\",\n",
    "        \"id\",\n",
    "        \"experiment_nm\",\n",
    "        \"test_nm\",\n",
    "        # \"based_on/slurm_id\",\n",
    "        \"relation-model/class\",\n",
    "        \"img_size\",\n",
    "        \"batch_size\",\n",
    "        # \"model/auxiliary_loss_ratio\",\n",
    "        # \"model/num_slots\",\n",
    "        # \"model/num_iterations\",\n",
    "        # \"model/hid_dim\",\n",
    "        \"max_epoch\",\n",
    "        \"val/loss\",\n",
    "        f\"train/{dataset}/accuracy\",\n",
    "        f\"val/{dataset}/accuracy\",\n",
    "        # TODO: Add Test results for each regime)\n",
    "        \"based_on\",\n",
    "        \"finetune_from\",\n",
    "        \"is_double\",\n",
    "    ]\n",
    "    test_cols = [\n",
    "        f\"test/{dataset}/{test_type}\"\n",
    "        for test_type in map(\n",
    "            lambda x: x[1], filter(lambda x: x[0] == dataset, test_types)\n",
    "        )\n",
    "    ]\n",
    "    _df = df_esnb[[*cols, *test_cols]]\n",
    "    # _df[\"model/auxiliary_loss_ratio\"] = (\n",
    "    #     _df[\"model/auxiliary_loss_ratio\"].fillna(0).astype(\"int\")\n",
    "    # )\n",
    "    _df.wandb_urls = _df.wandb_urls.str.split(\"/\").str[-1]\n",
    "    _df = _df.dropna(subset=[f\"train/{dataset}/accuracy\", f\"val/{dataset}/accuracy\"])\n",
    "    _df.dataset = dataset\n",
    "    _df[\"relation-model/class\"] = _df[\"relation-model/class\"].str.split(\".\").str[2]\n",
    "    _df.max_epoch = _df.max_epoch.astype(\"Int32\")\n",
    "\n",
    "    out = []\n",
    "    for column in _df.columns:\n",
    "        splt = column.split(\"/\")\n",
    "        if len(splt) == 3:\n",
    "            out.append((splt[0], splt[1], splt[2]))\n",
    "        elif len(splt) == 2:\n",
    "            if splt[0] in [\"train\", \"val\", \"test\"]:\n",
    "                out.append((splt[0], \"\", splt[1]))\n",
    "                continue\n",
    "            if column == \"model/auxilary_loss_ratio\":\n",
    "                out.append((\"auxiliary\", \"loss\", \"ratio\"))\n",
    "                continue\n",
    "            out.append((\"\", splt[0], splt[1]))\n",
    "        else:\n",
    "            out.append((\"\", \"\", splt[0]))\n",
    "    _df.columns = pd.MultiIndex.from_tuples(out)\n",
    "    # _df.loc[:,\"test\"] = _df.apply(\n",
    "    #     lambda x: f'{\", \".join([f\"{x[col]:.2%}\" for col in test_cols if not pd.isna(x[col])])}',\n",
    "    #     axis=1,\n",
    "    # )\n",
    "    # _df.wandb_urls = _df.wandb_urls.str.split(\"/\").str[-1]\n",
    "    print(f\"\\n%{'-'*20} {dataset} {'-'*20}\\n\")\n",
    "\n",
    "    _highlight_max = [\n",
    "        f\"train/{dataset}/accuracy\",\n",
    "        f\"val/{dataset}/accuracy\",\n",
    "        *test_cols,\n",
    "    ]\n",
    "    _highlight_max = [col.split(\"/\") for col in _highlight_max]\n",
    "    _tbl = (\n",
    "        _df.style.highlight_max(\n",
    "            # subset=[f\"train/{dataset}/accuracy\", f\"val/{dataset}/accuracy\", *test_cols],\n",
    "            subset=_highlight_max,\n",
    "            axis=0,\n",
    "            props=\"textbf:--rwrap;\",\n",
    "        )\n",
    "        .highlight_min(\n",
    "            subset=[(\"val\", \"\", \"loss\")],\n",
    "            axis=0,\n",
    "            props=\"textbf:--rwrap;\",\n",
    "        )\n",
    "        .hide()\n",
    "        .format(\n",
    "            formatter=\"{:.2%}\".format,\n",
    "            subset=[\n",
    "                *_highlight_max,\n",
    "                (\"train\", dataset, \"accuracy\"),\n",
    "                (\"val\", dataset, \"accuracy\"),\n",
    "            ],\n",
    "        )\n",
    "        .to_latex(\n",
    "            caption=f\"Classification results for {dataset}\",\n",
    "            hrules=True,\n",
    "            label=f\"tab:pretrain-{dataset.replace('_', '-')}\",\n",
    "            # siunitx=True,\n",
    "            # column_format=\"lp{0.5cm}p{1.8cm}p{1.5cm}p{1.0cm}p{0.7cm}p{0.7cm}p{0.7cm}p{0.6cm}p{0.6cm}p{0.4cm}p{0.4cm}p{0.5cm}\"\n",
    "            # + len(test_cols) * \"p{0.4cm}\",\n",
    "            multicol_align=\"c\",\n",
    "        )\n",
    "        .replace(\"finetune_on_single_task_based_on_dual\", \"finetune\")\n",
    "        .replace(\"_\", \"\\\\_\")\n",
    "        .replace(\"nan%\", \"---\")\n",
    "        .replace(\"nan\", \"---\")\n",
    "        .replace(\"%\", \"\\%\")\n",
    "    )\n",
    "    # add \\resizebox{\\textwidth}{!}{% ... } between tabular and end tabular\n",
    "    _tbl = _tbl.replace(\n",
    "        r\"\\begin{tabular}\",\n",
    "        r\"\"\"\\resizebox{\\textwidth}{!}{%\n",
    "\\begin{tabular}\"\"\",\n",
    "    )\n",
    "\n",
    "    _tbl = _tbl.replace(\n",
    "        r\"\\end{tabular}\",\n",
    "        r\"\"\"\\end{tabular}\n",
    "}\"\"\",\n",
    "    )\n",
    "\n",
    "    display(_df.shape)\n",
    "    display(_df)\n",
    "    # print(_tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show top results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test/bongard_logo/test_bd</th>\n",
       "      <th>wandb_urls</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>based_on/slurm_id</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>finetuned_from_slurm_id</th>\n",
       "      <th>val/bongard_logo/accuracy</th>\n",
       "      <th>val/bongard_logo/mse_loss</th>\n",
       "      <th>train/bongard_logo/mse_loss_epoch</th>\n",
       "      <th>train/bongard_logo/accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.950000</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>883839.0</td>\n",
       "      <td>0.865556</td>\n",
       "      <td>0.007597</td>\n",
       "      <td>0.007367</td>\n",
       "      <td>0.868710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0.950000</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252</td>\n",
       "      <td>883823.0</td>\n",
       "      <td>0.887778</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.007768</td>\n",
       "      <td>0.893548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0.941667</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251</td>\n",
       "      <td>883827.0</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.860108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.881250</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_logo_scoring</td>\n",
       "      <td>frozen_slot</td>\n",
       "      <td>871045.0</td>\n",
       "      <td>413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.807778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.822796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.864583</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_logo_scoring</td>\n",
       "      <td>trained_slot_aux_test</td>\n",
       "      <td>871045.0</td>\n",
       "      <td>174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.764194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test/bongard_logo/test_bd  \\\n",
       "290                   0.950000   \n",
       "282                   0.950000   \n",
       "284                   0.941667   \n",
       "25                    0.881250   \n",
       "54                    0.864583   \n",
       "\n",
       "                                            wandb_urls         experiment_nm  \\\n",
       "290  https://wandb.ai/avr_universal/AVR_universal/r...              finetune   \n",
       "282  https://wandb.ai/avr_universal/AVR_universal/r...              finetune   \n",
       "284  https://wandb.ai/avr_universal/AVR_universal/r...              finetune   \n",
       "25   https://wandb.ai/avr_universal/AVR_universal/r...  bongard_logo_scoring   \n",
       "54   https://wandb.ai/avr_universal/AVR_universal/r...  bongard_logo_scoring   \n",
       "\n",
       "                                   test_nm  based_on/slurm_id  max_epoch  \\\n",
       "290  finetune_on_single_task_based_on_dual                NaN        140   \n",
       "282  finetune_on_single_task_based_on_dual                NaN        252   \n",
       "284  finetune_on_single_task_based_on_dual                NaN        251   \n",
       "25                             frozen_slot           871045.0        413   \n",
       "54                   trained_slot_aux_test           871045.0        174   \n",
       "\n",
       "     finetuned_from_slurm_id  val/bongard_logo/accuracy  \\\n",
       "290                 883839.0                   0.865556   \n",
       "282                 883823.0                   0.887778   \n",
       "284                 883827.0                   0.846667   \n",
       "25                       NaN                   0.807778   \n",
       "54                       NaN                   0.773333   \n",
       "\n",
       "     val/bongard_logo/mse_loss  train/bongard_logo/mse_loss_epoch  \\\n",
       "290                   0.007597                           0.007367   \n",
       "282                   0.007941                           0.007768   \n",
       "284                   0.001510                           0.001455   \n",
       "25                         NaN                                NaN   \n",
       "54                    0.000941                           0.000931   \n",
       "\n",
       "     train/bongard_logo/accuracy  \n",
       "290                     0.868710  \n",
       "282                     0.893548  \n",
       "284                     0.860108  \n",
       "25                      0.822796  \n",
       "54                      0.764194  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test/bongard_logo/test_ff</th>\n",
       "      <th>wandb_urls</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>based_on/slurm_id</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>finetuned_from_slurm_id</th>\n",
       "      <th>val/bongard_logo/accuracy</th>\n",
       "      <th>val/bongard_logo/mse_loss</th>\n",
       "      <th>train/bongard_logo/mse_loss_epoch</th>\n",
       "      <th>train/bongard_logo/accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0.915000</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252</td>\n",
       "      <td>883823.0</td>\n",
       "      <td>0.887778</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.007768</td>\n",
       "      <td>0.893548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.873333</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>883839.0</td>\n",
       "      <td>0.865556</td>\n",
       "      <td>0.007597</td>\n",
       "      <td>0.007367</td>\n",
       "      <td>0.868710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0.836667</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251</td>\n",
       "      <td>883827.0</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.860108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.771667</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>253</td>\n",
       "      <td>883831.0</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.813118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.765000</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_logo_scoring</td>\n",
       "      <td>frozen_slot</td>\n",
       "      <td>871045.0</td>\n",
       "      <td>413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.807778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.822796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test/bongard_logo/test_ff  \\\n",
       "282                   0.915000   \n",
       "290                   0.873333   \n",
       "284                   0.836667   \n",
       "286                   0.771667   \n",
       "25                    0.765000   \n",
       "\n",
       "                                            wandb_urls         experiment_nm  \\\n",
       "282  https://wandb.ai/avr_universal/AVR_universal/r...              finetune   \n",
       "290  https://wandb.ai/avr_universal/AVR_universal/r...              finetune   \n",
       "284  https://wandb.ai/avr_universal/AVR_universal/r...              finetune   \n",
       "286  https://wandb.ai/avr_universal/AVR_universal/r...              finetune   \n",
       "25   https://wandb.ai/avr_universal/AVR_universal/r...  bongard_logo_scoring   \n",
       "\n",
       "                                   test_nm  based_on/slurm_id  max_epoch  \\\n",
       "282  finetune_on_single_task_based_on_dual                NaN        252   \n",
       "290  finetune_on_single_task_based_on_dual                NaN        140   \n",
       "284  finetune_on_single_task_based_on_dual                NaN        251   \n",
       "286  finetune_on_single_task_based_on_dual                NaN        253   \n",
       "25                             frozen_slot           871045.0        413   \n",
       "\n",
       "     finetuned_from_slurm_id  val/bongard_logo/accuracy  \\\n",
       "282                 883823.0                   0.887778   \n",
       "290                 883839.0                   0.865556   \n",
       "284                 883827.0                   0.846667   \n",
       "286                 883831.0                   0.811111   \n",
       "25                       NaN                   0.807778   \n",
       "\n",
       "     val/bongard_logo/mse_loss  train/bongard_logo/mse_loss_epoch  \\\n",
       "282                   0.007941                           0.007768   \n",
       "290                   0.007597                           0.007367   \n",
       "284                   0.001510                           0.001455   \n",
       "286                   0.000931                           0.000945   \n",
       "25                         NaN                                NaN   \n",
       "\n",
       "     train/bongard_logo/accuracy  \n",
       "282                     0.893548  \n",
       "290                     0.868710  \n",
       "284                     0.860108  \n",
       "286                     0.813118  \n",
       "25                      0.822796  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test/bongard_logo/test_hd_comb</th>\n",
       "      <th>wandb_urls</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>based_on/slurm_id</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>finetuned_from_slurm_id</th>\n",
       "      <th>val/bongard_logo/accuracy</th>\n",
       "      <th>val/bongard_logo/mse_loss</th>\n",
       "      <th>train/bongard_logo/mse_loss_epoch</th>\n",
       "      <th>train/bongard_logo/accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.7425</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>253</td>\n",
       "      <td>883831.0</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.813118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.7250</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_logo_combined_transformer_v4</td>\n",
       "      <td>transformer_scoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.979677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0.7175</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252</td>\n",
       "      <td>883823.0</td>\n",
       "      <td>0.887778</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.007768</td>\n",
       "      <td>0.893548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.7100</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_logo_scoring</td>\n",
       "      <td>frozen_slot</td>\n",
       "      <td>871045.0</td>\n",
       "      <td>413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.807778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.822796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.7100</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_logo_combined_v4_agg</td>\n",
       "      <td>no_context_parameter_search</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.784444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test/bongard_logo/test_hd_comb  \\\n",
       "286                          0.7425   \n",
       "199                          0.7250   \n",
       "282                          0.7175   \n",
       "25                           0.7100   \n",
       "181                          0.7100   \n",
       "\n",
       "                                            wandb_urls  \\\n",
       "286  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "199  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "282  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "25   https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "181  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "\n",
       "                            experiment_nm  \\\n",
       "286                              finetune   \n",
       "199  bongard_logo_combined_transformer_v4   \n",
       "282                              finetune   \n",
       "25                   bongard_logo_scoring   \n",
       "181          bongard_logo_combined_v4_agg   \n",
       "\n",
       "                                   test_nm  based_on/slurm_id  max_epoch  \\\n",
       "286  finetune_on_single_task_based_on_dual                NaN        253   \n",
       "199                    transformer_scoring                NaN        102   \n",
       "282  finetune_on_single_task_based_on_dual                NaN        252   \n",
       "25                             frozen_slot           871045.0        413   \n",
       "181            no_context_parameter_search                NaN        146   \n",
       "\n",
       "     finetuned_from_slurm_id  val/bongard_logo/accuracy  \\\n",
       "286                 883831.0                   0.811111   \n",
       "199                      NaN                   0.777778   \n",
       "282                 883823.0                   0.887778   \n",
       "25                       NaN                   0.807778   \n",
       "181                      NaN                   0.784444   \n",
       "\n",
       "     val/bongard_logo/mse_loss  train/bongard_logo/mse_loss_epoch  \\\n",
       "286                   0.000931                           0.000945   \n",
       "199                        NaN                                NaN   \n",
       "282                   0.007941                           0.007768   \n",
       "25                         NaN                                NaN   \n",
       "181                        NaN                                NaN   \n",
       "\n",
       "     train/bongard_logo/accuracy  \n",
       "286                     0.813118  \n",
       "199                     0.979677  \n",
       "282                     0.893548  \n",
       "25                      0.822796  \n",
       "181                     0.968817  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test/bongard_logo/test_hd_novel</th>\n",
       "      <th>wandb_urls</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>based_on/slurm_id</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>finetuned_from_slurm_id</th>\n",
       "      <th>val/bongard_logo/accuracy</th>\n",
       "      <th>val/bongard_logo/mse_loss</th>\n",
       "      <th>train/bongard_logo/mse_loss_epoch</th>\n",
       "      <th>train/bongard_logo/accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.765625</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_logo_combined_transformer_v4</td>\n",
       "      <td>small_transformer_scoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.763333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.765625</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_logo_combined_transformer_v4</td>\n",
       "      <td>transformer_scoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.979677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.753125</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_logo_combined_v2</td>\n",
       "      <td>asymmetric_only_parameter_search</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.778889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.743750</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_logo_combined_v4_agg</td>\n",
       "      <td>no_context_parameter_search</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.784444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.743750</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_logo_combined_v4_agg</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.797778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.916344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test/bongard_logo/test_hd_novel  \\\n",
       "195                         0.765625   \n",
       "199                         0.765625   \n",
       "165                         0.753125   \n",
       "181                         0.743750   \n",
       "155                         0.743750   \n",
       "\n",
       "                                            wandb_urls  \\\n",
       "195  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "199  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "165  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "181  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "155  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "\n",
       "                            experiment_nm                           test_nm  \\\n",
       "195  bongard_logo_combined_transformer_v4         small_transformer_scoring   \n",
       "199  bongard_logo_combined_transformer_v4               transformer_scoring   \n",
       "165              bongard_logo_combined_v2  asymmetric_only_parameter_search   \n",
       "181          bongard_logo_combined_v4_agg       no_context_parameter_search   \n",
       "155          bongard_logo_combined_v4_agg                          baseline   \n",
       "\n",
       "     based_on/slurm_id  max_epoch  finetuned_from_slurm_id  \\\n",
       "195                NaN        101                      NaN   \n",
       "199                NaN        102                      NaN   \n",
       "165                NaN        116                      NaN   \n",
       "181                NaN        146                      NaN   \n",
       "155                NaN        231                      NaN   \n",
       "\n",
       "     val/bongard_logo/accuracy  val/bongard_logo/mse_loss  \\\n",
       "195                   0.763333                        NaN   \n",
       "199                   0.777778                        NaN   \n",
       "165                   0.778889                        NaN   \n",
       "181                   0.784444                        NaN   \n",
       "155                   0.797778                        NaN   \n",
       "\n",
       "     train/bongard_logo/mse_loss_epoch  train/bongard_logo/accuracy  \n",
       "195                                NaN                     0.987097  \n",
       "199                                NaN                     0.979677  \n",
       "165                                NaN                     0.976774  \n",
       "181                                NaN                     0.968817  \n",
       "155                                NaN                     0.916344  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test/vaec/test1</th>\n",
       "      <th>wandb_urls</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>based_on/slurm_id</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>finetuned_from_slurm_id</th>\n",
       "      <th>val/vaec/accuracy</th>\n",
       "      <th>val/vaec/mse_loss</th>\n",
       "      <th>train/vaec/mse_loss_epoch</th>\n",
       "      <th>train/vaec/accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.996722</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_scoring</td>\n",
       "      <td>trained_slot_aux_test</td>\n",
       "      <td>871052.0</td>\n",
       "      <td>114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997057</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.994131</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_scoring</td>\n",
       "      <td>train_slot_no_aux</td>\n",
       "      <td>871037.0</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.994089</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151</td>\n",
       "      <td>883827.0</td>\n",
       "      <td>0.995994</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.988054</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_scoring</td>\n",
       "      <td>train_slot_no_aux</td>\n",
       "      <td>871052.0</td>\n",
       "      <td>115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.988237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.986088</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_scoring</td>\n",
       "      <td>trained_slot_aux_test</td>\n",
       "      <td>871039.0</td>\n",
       "      <td>208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987817</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test/vaec/test1                                         wandb_urls  \\\n",
       "61          0.996722  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "33          0.994131  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "285         0.994089  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "37          0.988054  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "46          0.986088  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "\n",
       "    experiment_nm                                test_nm  based_on/slurm_id  \\\n",
       "61   vaec_scoring                  trained_slot_aux_test           871052.0   \n",
       "33   vaec_scoring                      train_slot_no_aux           871037.0   \n",
       "285      finetune  finetune_on_single_task_based_on_dual                NaN   \n",
       "37   vaec_scoring                      train_slot_no_aux           871052.0   \n",
       "46   vaec_scoring                  trained_slot_aux_test           871039.0   \n",
       "\n",
       "     max_epoch  finetuned_from_slurm_id  val/vaec/accuracy  val/vaec/mse_loss  \\\n",
       "61         114                      NaN           0.997057           0.001574   \n",
       "33          73                      NaN           0.993889                NaN   \n",
       "285        151                 883827.0           0.995994           0.000328   \n",
       "37         115                      NaN           0.988237                NaN   \n",
       "46         208                      NaN           0.987817           0.002804   \n",
       "\n",
       "     train/vaec/mse_loss_epoch  train/vaec/accuracy  \n",
       "61                    0.000015                  1.0  \n",
       "33                         NaN                  1.0  \n",
       "285                   0.000005                  1.0  \n",
       "37                         NaN                  1.0  \n",
       "46                    0.000661                  1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test/vaec/test2</th>\n",
       "      <th>wandb_urls</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>based_on/slurm_id</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>finetuned_from_slurm_id</th>\n",
       "      <th>val/vaec/accuracy</th>\n",
       "      <th>val/vaec/mse_loss</th>\n",
       "      <th>train/vaec/mse_loss_epoch</th>\n",
       "      <th>train/vaec/accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.868881</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_scoring</td>\n",
       "      <td>train_slot_no_aux</td>\n",
       "      <td>871037.0</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.864647</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_scoring</td>\n",
       "      <td>trained_slot_aux_test</td>\n",
       "      <td>871039.0</td>\n",
       "      <td>208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987817</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.831056</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>finetune</td>\n",
       "      <td>finetune_on_single_task_based_on_dual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151</td>\n",
       "      <td>883827.0</td>\n",
       "      <td>0.995994</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.813528</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_scoring</td>\n",
       "      <td>trained_slot_aux_test</td>\n",
       "      <td>871052.0</td>\n",
       "      <td>114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997057</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.782212</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_scoring</td>\n",
       "      <td>trained_slot_aux_test</td>\n",
       "      <td>871039.0</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.959347</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.997632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test/vaec/test2                                         wandb_urls  \\\n",
       "33          0.868881  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "46          0.864647  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "285         0.831056  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "61          0.813528  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "47          0.782212  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "\n",
       "    experiment_nm                                test_nm  based_on/slurm_id  \\\n",
       "33   vaec_scoring                      train_slot_no_aux           871037.0   \n",
       "46   vaec_scoring                  trained_slot_aux_test           871039.0   \n",
       "285      finetune  finetune_on_single_task_based_on_dual                NaN   \n",
       "61   vaec_scoring                  trained_slot_aux_test           871052.0   \n",
       "47   vaec_scoring                  trained_slot_aux_test           871039.0   \n",
       "\n",
       "     max_epoch  finetuned_from_slurm_id  val/vaec/accuracy  val/vaec/mse_loss  \\\n",
       "33          73                      NaN           0.993889                NaN   \n",
       "46         208                      NaN           0.987817           0.002804   \n",
       "285        151                 883827.0           0.995994           0.000328   \n",
       "61         114                      NaN           0.997057           0.001574   \n",
       "47          37                      NaN           0.959347           0.002243   \n",
       "\n",
       "     train/vaec/mse_loss_epoch  train/vaec/accuracy  \n",
       "33                         NaN             1.000000  \n",
       "46                    0.000661             1.000000  \n",
       "285                   0.000005             1.000000  \n",
       "61                    0.000015             1.000000  \n",
       "47                    0.000034             0.997632  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test/vaec/test3</th>\n",
       "      <th>wandb_urls</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>based_on/slurm_id</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>finetuned_from_slurm_id</th>\n",
       "      <th>val/vaec/accuracy</th>\n",
       "      <th>val/vaec/mse_loss</th>\n",
       "      <th>train/vaec/mse_loss_epoch</th>\n",
       "      <th>train/vaec/accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.799392</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_scoring</td>\n",
       "      <td>train_slot_no_aux</td>\n",
       "      <td>871037.0</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.678330</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_combined_v2</td>\n",
       "      <td>symmetric_only_parameter_search</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.639953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.807199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.673718</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_combined_v4</td>\n",
       "      <td>hoi_module_substitute</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.631460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.735934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.661304</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_combined_v4</td>\n",
       "      <td>vasr_module_substitute</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.736673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0.649691</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_combined_v2</td>\n",
       "      <td>combined_bongard_hoi_bongard_logo_fine_tune_no...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.615746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.818657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test/vaec/test3                                         wandb_urls  \\\n",
       "33          0.799392  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "163         0.678330  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "246         0.673718  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "249         0.661304  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "263         0.649691  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "\n",
       "        experiment_nm                                            test_nm  \\\n",
       "33       vaec_scoring                                  train_slot_no_aux   \n",
       "163  vaec_combined_v2                    symmetric_only_parameter_search   \n",
       "246  vaec_combined_v4                              hoi_module_substitute   \n",
       "249  vaec_combined_v4                             vasr_module_substitute   \n",
       "263  vaec_combined_v2  combined_bongard_hoi_bongard_logo_fine_tune_no...   \n",
       "\n",
       "     based_on/slurm_id  max_epoch  finetuned_from_slurm_id  val/vaec/accuracy  \\\n",
       "33            871037.0         73                      NaN           0.993889   \n",
       "163                NaN        137                      NaN           0.639953   \n",
       "246                NaN        161                      NaN           0.631460   \n",
       "249                NaN        179                      NaN           0.619735   \n",
       "263                NaN        261                      NaN           0.615746   \n",
       "\n",
       "     val/vaec/mse_loss  train/vaec/mse_loss_epoch  train/vaec/accuracy  \n",
       "33                 NaN                        NaN             1.000000  \n",
       "163                NaN                        NaN             0.807199  \n",
       "246                NaN                        NaN             0.735934  \n",
       "249                NaN                        NaN             0.736673  \n",
       "263                NaN                        NaN             0.818657  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test/vaec/test4</th>\n",
       "      <th>wandb_urls</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>based_on/slurm_id</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>finetuned_from_slurm_id</th>\n",
       "      <th>val/vaec/accuracy</th>\n",
       "      <th>val/vaec/mse_loss</th>\n",
       "      <th>train/vaec/mse_loss_epoch</th>\n",
       "      <th>train/vaec/accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.613046</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_combined_v4</td>\n",
       "      <td>hoi_module_substitute</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.631460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.735934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.611865</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_combined_v2</td>\n",
       "      <td>symmetric_only_parameter_search</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.639953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.807199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.606161</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_combined_v4</td>\n",
       "      <td>vasr_module_substitute</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.736673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.583775</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_bongard_logo_combined_v4</td>\n",
       "      <td>common_relationals_common_scoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.669087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.951678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.583268</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_hoi_vaec_combined_v5</td>\n",
       "      <td>common_relationals_separate_scoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test/vaec/test4                                         wandb_urls  \\\n",
       "246         0.613046  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "163         0.611865  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "249         0.606161  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "224         0.583775  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "227         0.583268  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "\n",
       "                     experiment_nm                              test_nm  \\\n",
       "246               vaec_combined_v4                hoi_module_substitute   \n",
       "163               vaec_combined_v2      symmetric_only_parameter_search   \n",
       "249               vaec_combined_v4               vasr_module_substitute   \n",
       "224  vaec_bongard_logo_combined_v4    common_relationals_common_scoring   \n",
       "227   bongard_hoi_vaec_combined_v5  common_relationals_separate_scoring   \n",
       "\n",
       "     based_on/slurm_id  max_epoch  finetuned_from_slurm_id  val/vaec/accuracy  \\\n",
       "246                NaN        161                      NaN           0.631460   \n",
       "163                NaN        137                      NaN           0.639953   \n",
       "249                NaN        179                      NaN           0.619735   \n",
       "224                NaN        106                      NaN           0.669087   \n",
       "227                NaN        103                      NaN           0.661649   \n",
       "\n",
       "     val/vaec/mse_loss  train/vaec/mse_loss_epoch  train/vaec/accuracy  \n",
       "246                NaN                        NaN             0.735934  \n",
       "163                NaN                        NaN             0.807199  \n",
       "249                NaN                        NaN             0.736673  \n",
       "224                NaN                        NaN             0.951678  \n",
       "227                NaN                        NaN             0.991683  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test/vaec/test5</th>\n",
       "      <th>wandb_urls</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>based_on/slurm_id</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>finetuned_from_slurm_id</th>\n",
       "      <th>val/vaec/accuracy</th>\n",
       "      <th>val/vaec/mse_loss</th>\n",
       "      <th>train/vaec/mse_loss_epoch</th>\n",
       "      <th>train/vaec/accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.661281</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_combined_v2</td>\n",
       "      <td>symmetric_only_parameter_search</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.639953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.807199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.660795</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_combined_v4</td>\n",
       "      <td>vasr_module_substitute</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.736673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.659285</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_combined_v4</td>\n",
       "      <td>hoi_module_substitute</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.631460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.735934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0.628278</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_combined_v2</td>\n",
       "      <td>combined_bongard_hoi_bongard_logo_fine_tune_no...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.615746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.818657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.626817</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vaec_combined_v2</td>\n",
       "      <td>combined_vasr_vaec_fine_tune_no_asymetric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.793207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test/vaec/test5                                         wandb_urls  \\\n",
       "163         0.661281  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "249         0.660795  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "246         0.659285  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "263         0.628278  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "271         0.626817  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "\n",
       "        experiment_nm                                            test_nm  \\\n",
       "163  vaec_combined_v2                    symmetric_only_parameter_search   \n",
       "249  vaec_combined_v4                             vasr_module_substitute   \n",
       "246  vaec_combined_v4                              hoi_module_substitute   \n",
       "263  vaec_combined_v2  combined_bongard_hoi_bongard_logo_fine_tune_no...   \n",
       "271  vaec_combined_v2          combined_vasr_vaec_fine_tune_no_asymetric   \n",
       "\n",
       "     based_on/slurm_id  max_epoch  finetuned_from_slurm_id  val/vaec/accuracy  \\\n",
       "163                NaN        137                      NaN           0.639953   \n",
       "249                NaN        179                      NaN           0.619735   \n",
       "246                NaN        161                      NaN           0.631460   \n",
       "263                NaN        261                      NaN           0.615746   \n",
       "271                NaN        214                      NaN           0.605286   \n",
       "\n",
       "     val/vaec/mse_loss  train/vaec/mse_loss_epoch  train/vaec/accuracy  \n",
       "163                NaN                        NaN             0.807199  \n",
       "249                NaN                        NaN             0.736673  \n",
       "246                NaN                        NaN             0.735934  \n",
       "263                NaN                        NaN             0.818657  \n",
       "271                NaN                        NaN             0.793207  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test/bongard_hoi/seen-seen</th>\n",
       "      <th>wandb_urls</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>based_on/slurm_id</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>finetuned_from_slurm_id</th>\n",
       "      <th>val/bongard_hoi/accuracy</th>\n",
       "      <th>val/bongard_hoi/mse_loss</th>\n",
       "      <th>train/bongard_hoi/mse_loss_epoch</th>\n",
       "      <th>train/bongard_hoi/accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.761727</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_hoi_combined_transformer_v4</td>\n",
       "      <td>transformer_scoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.760631</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_hoi_combined_v4_agg</td>\n",
       "      <td>mlp_hidden_dim_256_128_64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.754494</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_hoi_combined_v4_agg</td>\n",
       "      <td>mlp_hidden_dim_256_128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.827454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.977909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.751644</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_hoi_combined_v4_agg</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.832452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.979124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.749452</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_hoi_bongard_logo_combined_v4_agg</td>\n",
       "      <td>partial_freezing_hoi_0_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.829512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.964107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test/bongard_hoi/seen-seen  \\\n",
       "198                    0.761727   \n",
       "187                    0.760631   \n",
       "186                    0.754494   \n",
       "154                    0.751644   \n",
       "234                    0.749452   \n",
       "\n",
       "                                            wandb_urls  \\\n",
       "198  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "187  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "186  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "154  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "234  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "\n",
       "                                experiment_nm                    test_nm  \\\n",
       "198       bongard_hoi_combined_transformer_v4        transformer_scoring   \n",
       "187               bongard_hoi_combined_v4_agg  mlp_hidden_dim_256_128_64   \n",
       "186               bongard_hoi_combined_v4_agg     mlp_hidden_dim_256_128   \n",
       "154               bongard_hoi_combined_v4_agg                   baseline   \n",
       "234  bongard_hoi_bongard_logo_combined_v4_agg   partial_freezing_hoi_0_1   \n",
       "\n",
       "     based_on/slurm_id  max_epoch  finetuned_from_slurm_id  \\\n",
       "198                NaN         54                      NaN   \n",
       "187                NaN        101                      NaN   \n",
       "186                NaN        101                      NaN   \n",
       "154                NaN        101                      NaN   \n",
       "234                NaN        157                      NaN   \n",
       "\n",
       "     val/bongard_hoi/accuracy  val/bongard_hoi/mse_loss  \\\n",
       "198                  0.835097                       NaN   \n",
       "187                  0.837155                       NaN   \n",
       "186                  0.827454                       NaN   \n",
       "154                  0.832452                       NaN   \n",
       "234                  0.829512                       NaN   \n",
       "\n",
       "     train/bongard_hoi/mse_loss_epoch  train/bongard_hoi/accuracy  \n",
       "198                               NaN                    0.997917  \n",
       "187                               NaN                    0.987891  \n",
       "186                               NaN                    0.977909  \n",
       "154                               NaN                    0.979124  \n",
       "234                               NaN                    0.964107  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test/bongard_hoi/seen-unseen</th>\n",
       "      <th>wandb_urls</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>based_on/slurm_id</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>finetuned_from_slurm_id</th>\n",
       "      <th>val/bongard_hoi/accuracy</th>\n",
       "      <th>val/bongard_hoi/mse_loss</th>\n",
       "      <th>train/bongard_hoi/mse_loss_epoch</th>\n",
       "      <th>train/bongard_hoi/accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.857490</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_hoi_combined_v4_agg</td>\n",
       "      <td>mlp_hidden_dim_256_128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.827454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.977909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.856882</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_hoi_combined_v4_agg</td>\n",
       "      <td>mlp_hidden_dim_256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.840388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.982423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.854148</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_hoi_combined_v4_agg</td>\n",
       "      <td>mlp_hidden_dim_256_128_64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.853540</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_hoi_combined_v4_agg</td>\n",
       "      <td>mlp_hidden_dim_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.828630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.852628</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_hoi_bongard_logo_combined_v5</td>\n",
       "      <td>common_relationals_separate_scoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.834803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.988542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test/bongard_hoi/seen-unseen  \\\n",
       "186                      0.857490   \n",
       "184                      0.856882   \n",
       "187                      0.854148   \n",
       "188                      0.853540   \n",
       "226                      0.852628   \n",
       "\n",
       "                                            wandb_urls  \\\n",
       "186  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "184  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "187  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "188  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "226  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "\n",
       "                            experiment_nm  \\\n",
       "186           bongard_hoi_combined_v4_agg   \n",
       "184           bongard_hoi_combined_v4_agg   \n",
       "187           bongard_hoi_combined_v4_agg   \n",
       "188           bongard_hoi_combined_v4_agg   \n",
       "226  bongard_hoi_bongard_logo_combined_v5   \n",
       "\n",
       "                                 test_nm  based_on/slurm_id  max_epoch  \\\n",
       "186               mlp_hidden_dim_256_128                NaN        101   \n",
       "184                   mlp_hidden_dim_256                NaN        100   \n",
       "187            mlp_hidden_dim_256_128_64                NaN        101   \n",
       "188                      mlp_hidden_dim_                NaN        101   \n",
       "226  common_relationals_separate_scoring                NaN        101   \n",
       "\n",
       "     finetuned_from_slurm_id  val/bongard_hoi/accuracy  \\\n",
       "186                      NaN                  0.827454   \n",
       "184                      NaN                  0.840388   \n",
       "187                      NaN                  0.837155   \n",
       "188                      NaN                  0.828630   \n",
       "226                      NaN                  0.834803   \n",
       "\n",
       "     val/bongard_hoi/mse_loss  train/bongard_hoi/mse_loss_epoch  \\\n",
       "186                       NaN                               NaN   \n",
       "184                       NaN                               NaN   \n",
       "187                       NaN                               NaN   \n",
       "188                       NaN                               NaN   \n",
       "226                       NaN                               NaN   \n",
       "\n",
       "     train/bongard_hoi/accuracy  \n",
       "186                    0.977909  \n",
       "184                    0.982423  \n",
       "187                    0.987891  \n",
       "188                    0.989627  \n",
       "226                    0.988542  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test/bongard_hoi/unseen-seen</th>\n",
       "      <th>wandb_urls</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>based_on/slurm_id</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>finetuned_from_slurm_id</th>\n",
       "      <th>val/bongard_hoi/accuracy</th>\n",
       "      <th>val/bongard_hoi/mse_loss</th>\n",
       "      <th>train/bongard_hoi/mse_loss_epoch</th>\n",
       "      <th>train/bongard_hoi/accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.761727</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_hoi_combined_transformer_v4</td>\n",
       "      <td>transformer_scoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.760631</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_hoi_combined_v4_agg</td>\n",
       "      <td>mlp_hidden_dim_256_128_64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.754494</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_hoi_combined_v4_agg</td>\n",
       "      <td>mlp_hidden_dim_256_128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.827454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.977909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.751644</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_hoi_combined_v4_agg</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.832452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.979124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.749452</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_hoi_bongard_logo_combined_v4_agg</td>\n",
       "      <td>partial_freezing_hoi_0_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.829512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.964107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test/bongard_hoi/unseen-seen  \\\n",
       "198                      0.761727   \n",
       "187                      0.760631   \n",
       "186                      0.754494   \n",
       "154                      0.751644   \n",
       "234                      0.749452   \n",
       "\n",
       "                                            wandb_urls  \\\n",
       "198  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "187  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "186  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "154  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "234  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "\n",
       "                                experiment_nm                    test_nm  \\\n",
       "198       bongard_hoi_combined_transformer_v4        transformer_scoring   \n",
       "187               bongard_hoi_combined_v4_agg  mlp_hidden_dim_256_128_64   \n",
       "186               bongard_hoi_combined_v4_agg     mlp_hidden_dim_256_128   \n",
       "154               bongard_hoi_combined_v4_agg                   baseline   \n",
       "234  bongard_hoi_bongard_logo_combined_v4_agg   partial_freezing_hoi_0_1   \n",
       "\n",
       "     based_on/slurm_id  max_epoch  finetuned_from_slurm_id  \\\n",
       "198                NaN         54                      NaN   \n",
       "187                NaN        101                      NaN   \n",
       "186                NaN        101                      NaN   \n",
       "154                NaN        101                      NaN   \n",
       "234                NaN        157                      NaN   \n",
       "\n",
       "     val/bongard_hoi/accuracy  val/bongard_hoi/mse_loss  \\\n",
       "198                  0.835097                       NaN   \n",
       "187                  0.837155                       NaN   \n",
       "186                  0.827454                       NaN   \n",
       "154                  0.832452                       NaN   \n",
       "234                  0.829512                       NaN   \n",
       "\n",
       "     train/bongard_hoi/mse_loss_epoch  train/bongard_hoi/accuracy  \n",
       "198                               NaN                    0.997917  \n",
       "187                               NaN                    0.987891  \n",
       "186                               NaN                    0.977909  \n",
       "154                               NaN                    0.979124  \n",
       "234                               NaN                    0.964107  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test/bongard_hoi/unseen-unseen</th>\n",
       "      <th>wandb_urls</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>based_on/slurm_id</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>finetuned_from_slurm_id</th>\n",
       "      <th>val/bongard_hoi/accuracy</th>\n",
       "      <th>val/bongard_hoi/mse_loss</th>\n",
       "      <th>train/bongard_hoi/mse_loss_epoch</th>\n",
       "      <th>train/bongard_hoi/accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.818859</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_hoi_combined_v2</td>\n",
       "      <td>symmetric_only_parameter_search</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.830394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.920793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.815757</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_hoi_combined_v4_agg</td>\n",
       "      <td>mlp_hidden_dim_64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.986589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.815136</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_hoi_combined_v4_agg</td>\n",
       "      <td>mlp_hidden_dim_256_128_64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.813275</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_hoi_vaec_combined_v5</td>\n",
       "      <td>common_relationals_separate_scoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.831276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.809553</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>bongard_hoi_bongard_logo_combined_v4_agg</td>\n",
       "      <td>partial_freezing_hoi_0_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.829512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.964107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test/bongard_hoi/unseen-unseen  \\\n",
       "160                        0.818859   \n",
       "185                        0.815757   \n",
       "187                        0.815136   \n",
       "227                        0.813275   \n",
       "234                        0.809553   \n",
       "\n",
       "                                            wandb_urls  \\\n",
       "160  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "185  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "187  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "227  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "234  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "\n",
       "                                experiment_nm  \\\n",
       "160                   bongard_hoi_combined_v2   \n",
       "185               bongard_hoi_combined_v4_agg   \n",
       "187               bongard_hoi_combined_v4_agg   \n",
       "227              bongard_hoi_vaec_combined_v5   \n",
       "234  bongard_hoi_bongard_logo_combined_v4_agg   \n",
       "\n",
       "                                 test_nm  based_on/slurm_id  max_epoch  \\\n",
       "160      symmetric_only_parameter_search                NaN        119   \n",
       "185                    mlp_hidden_dim_64                NaN        100   \n",
       "187            mlp_hidden_dim_256_128_64                NaN        101   \n",
       "227  common_relationals_separate_scoring                NaN        103   \n",
       "234             partial_freezing_hoi_0_1                NaN        157   \n",
       "\n",
       "     finetuned_from_slurm_id  val/bongard_hoi/accuracy  \\\n",
       "160                      NaN                  0.830394   \n",
       "185                      NaN                  0.820988   \n",
       "187                      NaN                  0.837155   \n",
       "227                      NaN                  0.831276   \n",
       "234                      NaN                  0.829512   \n",
       "\n",
       "     val/bongard_hoi/mse_loss  train/bongard_hoi/mse_loss_epoch  \\\n",
       "160                       NaN                               NaN   \n",
       "185                       NaN                               NaN   \n",
       "187                       NaN                               NaN   \n",
       "227                       NaN                               NaN   \n",
       "234                       NaN                               NaN   \n",
       "\n",
       "     train/bongard_hoi/accuracy  \n",
       "160                    0.920793  \n",
       "185                    0.986589  \n",
       "187                    0.987891  \n",
       "227                    0.985982  \n",
       "234                    0.964107  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test/vasr/vasr</th>\n",
       "      <th>wandb_urls</th>\n",
       "      <th>experiment_nm</th>\n",
       "      <th>test_nm</th>\n",
       "      <th>based_on/slurm_id</th>\n",
       "      <th>max_epoch</th>\n",
       "      <th>finetuned_from_slurm_id</th>\n",
       "      <th>val/vasr/accuracy</th>\n",
       "      <th>val/vasr/mse_loss</th>\n",
       "      <th>train/vasr/mse_loss_epoch</th>\n",
       "      <th>train/vasr/accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.595039</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vasr_combined_v4</td>\n",
       "      <td>no_context_parameter_search</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.596076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.956527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.563144</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vasr_combined_v4</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.561884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.931823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.562642</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vasr_combined_v4</td>\n",
       "      <td>vasr_vaec_fine_tune</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.913625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.561662</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vasr_combined_v4</td>\n",
       "      <td>mlp_hidden_dim_256_128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.561408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.977587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.553994</td>\n",
       "      <td>https://wandb.ai/avr_universal/AVR_universal/r...</td>\n",
       "      <td>vasr_vaec_combined_v4</td>\n",
       "      <td>partial_freezing_vaec_0_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.911837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test/vasr/vasr                                         wandb_urls  \\\n",
       "182        0.595039  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "156        0.563144  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "212        0.562642  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "191        0.561662  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "243        0.553994  https://wandb.ai/avr_universal/AVR_universal/r...   \n",
       "\n",
       "             experiment_nm                      test_nm  based_on/slurm_id  \\\n",
       "182       vasr_combined_v4  no_context_parameter_search                NaN   \n",
       "156       vasr_combined_v4                     baseline                NaN   \n",
       "212       vasr_combined_v4          vasr_vaec_fine_tune                NaN   \n",
       "191       vasr_combined_v4       mlp_hidden_dim_256_128                NaN   \n",
       "243  vasr_vaec_combined_v4    partial_freezing_vaec_0_1                NaN   \n",
       "\n",
       "     max_epoch  finetuned_from_slurm_id  val/vasr/accuracy  val/vasr/mse_loss  \\\n",
       "182        100                      NaN           0.596076                NaN   \n",
       "156         81                      NaN           0.561884                NaN   \n",
       "212         61                      NaN           0.563879                NaN   \n",
       "191         75                      NaN           0.561408                NaN   \n",
       "243         64                      NaN           0.569186                NaN   \n",
       "\n",
       "     train/vasr/mse_loss_epoch  train/vasr/accuracy  \n",
       "182                        NaN             0.956527  \n",
       "156                        NaN             0.931823  \n",
       "212                        NaN             0.913625  \n",
       "191                        NaN             0.977587  \n",
       "243                        NaN             0.911837  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dataset, test_type in test_types:\n",
    "    _dataset_cols = [col for col in df.columns if dataset in col and \"test\" not in col]\n",
    "    cols = [\n",
    "        \"wandb_urls\",\n",
    "        \"experiment_nm\",\n",
    "        \"test_nm\",\n",
    "        \"based_on/slurm_id\",\n",
    "        \"max_epoch\",\n",
    "        \"finetuned_from_slurm_id\",\n",
    "        *_dataset_cols,\n",
    "    ]\n",
    "    display(\n",
    "        df[[f\"test/{dataset}/{test_type}\"] + cols]\n",
    "        .sort_values(f\"test/{dataset}/{test_type}\", ascending=False)\n",
    "        .head(5)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv(\"../../structured_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split by dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
